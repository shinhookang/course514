{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c-title",
   "metadata": {},
   "source": [
    "# Lab 06 (심화) — Classification: Advanced Topics\n",
    "\n",
    "\n",
    "> **전제 조건:** Lab 06 기본편 완료 (시그모이드, 소프트맥스, 기본 평가 지표)\n",
    "\n",
    "---\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "| # | 목표 | 예상 시간 |\n",
    "|---|---|---|\n",
    "| 1 | Dropout · BatchNorm — 정규화로 과적합 방지 | 15분 |\n",
    "| 2 | 클래스 불균형 — Weighted Loss · 오버샘플링 | 15분 |\n",
    "| 3 | 학습률 스케줄러 · 조기 종료 | 15분 |\n",
    "| 4 | 다중 클래스 ROC · Label Smoothing | 10분 |\n",
    "| 5 | Exercise | 5분 |\n",
    "\n",
    "---\n",
    "\n",
    "**데이터셋:** MNIST — 손글씨 숫자 분류 (불균형 버전 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix,\n",
    "    roc_curve, roc_auc_score\n",
    ")\n",
    "\n",
    "# 한글 폰트\n",
    "_fp = '/System/Library/Fonts/AppleGothic.ttf'\n",
    "fm.fontManager.addfont(_fp)\n",
    "plt.rcParams['font.family'] = fm.FontProperties(fname=_fp).get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "print('PyTorch:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── MNIST 로드 (기본편과 동일) ─────────────────────────────────────────\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "    mnist_tr_full = datasets.MNIST(root='/tmp/mnist', train=True,  download=True,\n",
    "                                   transform=transforms.ToTensor())\n",
    "    mnist_te_full = datasets.MNIST(root='/tmp/mnist', train=False, download=True,\n",
    "                                   transform=transforms.ToTensor())\n",
    "    X_tr_raw = mnist_tr_full.data.float().view(-1, 784) / 255.0\n",
    "    y_tr_raw = mnist_tr_full.targets\n",
    "    X_te_raw = mnist_te_full.data.float().view(-1, 784) / 255.0\n",
    "    y_te_raw = mnist_te_full.targets\n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    print('torchvision 없음 → sklearn MNIST')\n",
    "    _d = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "    _X = torch.tensor(_d.data.astype(np.float32) / 255.0)\n",
    "    _y = torch.tensor(_d.target.astype(np.int64))\n",
    "    X_tr_raw, X_te_raw = _X[:60000], _X[60000:]\n",
    "    y_tr_raw, y_te_raw = _y[:60000], _y[60000:]\n",
    "\n",
    "# 실습용 서브셋\n",
    "X_mn_tr = X_tr_raw[:6000]\n",
    "y_mn_tr = y_tr_raw[:6000]\n",
    "X_mn_te = X_te_raw[:1000]\n",
    "y_mn_te = y_te_raw[:1000]\n",
    "\n",
    "print(f'Train: {X_mn_tr.shape}  Test: {X_mn_te.shape}')\n",
    "\n",
    "# 공통 DataLoader 생성 함수\n",
    "def make_loader(X, y, batch_size=256, shuffle=True, sampler=None):\n",
    "    ds = TensorDataset(X, y)\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=(shuffle and sampler is None),\n",
    "                      sampler=sampler)\n",
    "\n",
    "train_loader = make_loader(X_mn_tr, y_mn_tr)\n",
    "test_loader  = make_loader(X_mn_te, y_mn_te, shuffle=False)\n",
    "\n",
    "# 공통 평가 함수\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, n = 0, 0, 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for xb, yb in loader:\n",
    "        out  = model(xb)\n",
    "        total_loss += criterion(out, yb).item() * len(xb)\n",
    "        correct    += (out.argmax(1) == yb).sum().item()\n",
    "        n          += len(xb)\n",
    "    return total_loss / n, correct / n\n",
    "\n",
    "print('데이터 준비 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. 정규화 기법 — Dropout & BatchNorm\n",
    "\n",
    "### 1-1. Dropout\n",
    "\n",
    "**Dropout**은 학습 중 뉴런을 무작위로 비활성화해 과적합을 방지합니다.\n",
    "\n",
    "```\n",
    "학습 시:  [0.3, 0.0, 0.8, 0.0, 0.5]  ← 뉴런 2개를 0으로\n",
    "추론 시:  [0.3, 0.4, 0.8, 0.1, 0.5]  ← 모든 뉴런 활성화 (스케일 보정)\n",
    "```\n",
    "\n",
    "**핵심 주의 사항:**\n",
    "- 학습: `model.train()` → Dropout **활성화**\n",
    "- 추론: `model.eval()` → Dropout **비활성화**\n",
    "- PyTorch는 `1/(1-p)` 스케일링을 자동 처리 (inverted dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 동작 원리 시각화\n",
    "torch.manual_seed(0)\n",
    "x_demo = torch.ones(1, 10) * 2.0   # 모든 값이 2인 벡터\n",
    "\n",
    "drop_layer = nn.Dropout(p=0.5)\n",
    "\n",
    "print('입력:', x_demo.numpy())\n",
    "print()\n",
    "drop_layer.train()\n",
    "for trial in range(5):\n",
    "    out = drop_layer(x_demo)\n",
    "    print(f'학습 모드 시도{trial+1}: {out.numpy()}  (합={out.sum():.1f})')\n",
    "print()\n",
    "drop_layer.eval()\n",
    "out_eval = drop_layer(x_demo)\n",
    "print(f'추론 모드      : {out_eval.numpy()}  (합={out_eval.sum():.1f})')\n",
    "print('→ eval 모드에서는 입력이 그대로 통과 (p=0으로 동작)')\n",
    "print('→ train 모드에서 1/(1-0.5)=2배 스케일링으로 기댓값 보존')\n",
    "\n",
    "# Dropout 비율별 활성화 패턴 시각화\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "x_vis = torch.randn(20, 20)\n",
    "for ax, p in zip(axes, [0.0, 0.2, 0.5, 0.8]):\n",
    "    d = nn.Dropout(p=p)\n",
    "    d.train()\n",
    "    mask = (d(torch.ones_like(x_vis)) > 0).float()\n",
    "    ax.imshow(mask, cmap='Blues', vmin=0, vmax=1)\n",
    "    ax.set_title(f'Dropout p={p}\\n활성 뉴런: {mask.mean():.0%}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Dropout 비율별 뉴런 활성화 패턴 (흰=비활성, 파랑=활성)', y=1.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md2",
   "metadata": {},
   "source": [
    "### 1-2. Batch Normalization\n",
    "\n",
    "**BatchNorm**은 미니배치 내에서 활성화값을 정규화합니다:\n",
    "\n",
    "$$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}, \\quad y_i = \\gamma\\hat{x}_i + \\beta$$\n",
    "\n",
    "- $\\mu_B, \\sigma_B$: 배치의 평균·표준편차 (학습 시 계산)\n",
    "- $\\gamma, \\beta$: 학습 가능한 스케일·시프트 파라미터\n",
    "\n",
    "**효과:**\n",
    "- Internal Covariate Shift 감소 → 더 높은 학습률 사용 가능\n",
    "- 약한 정규화 효과 (Dropout의 대안)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm 효과: 레이어 출력 분포 변화 시각화\n",
    "torch.manual_seed(42)\n",
    "x_bn = torch.randn(256, 128) * 5 + 3   # 평균 3, 표준편차 5\n",
    "\n",
    "bn_layer = nn.BatchNorm1d(128)\n",
    "bn_layer.eval()\n",
    "x_bn_out = bn_layer(x_bn).detach()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 3.5))\n",
    "axes[0].hist(x_bn[:, 0].numpy(), bins=40, color='tomato', edgecolor='white', alpha=0.85)\n",
    "axes[0].set_title(f'BatchNorm 전\\n(μ={x_bn[:,0].mean():.2f}, σ={x_bn[:,0].std():.2f})')\n",
    "axes[0].set_xlabel('활성화 값')\n",
    "\n",
    "axes[1].hist(x_bn_out[:, 0].numpy(), bins=40, color='steelblue', edgecolor='white', alpha=0.85)\n",
    "axes[1].set_title(f'BatchNorm 후\\n(μ={x_bn_out[:,0].mean():.2f}, σ={x_bn_out[:,0].std():.2f})')\n",
    "axes[1].set_xlabel('활성화 값')\n",
    "\n",
    "# 100개 특성의 평균/분산 분포\n",
    "axes[2].scatter(x_bn.mean(0).numpy(), x_bn.std(0).numpy(),\n",
    "                color='tomato', s=20, alpha=0.6, label='BN 전')\n",
    "axes[2].scatter(x_bn_out.mean(0).numpy(), x_bn_out.std(0).numpy(),\n",
    "                color='steelblue', s=20, alpha=0.6, label='BN 후')\n",
    "axes[2].set_title('특성별 평균 vs 표준편차\\n(BN 후 모든 특성이 μ≈0, σ≈1에 집중)')\n",
    "axes[2].set_xlabel('평균'); axes[2].set_ylabel('표준편차')\n",
    "axes[2].legend()\n",
    "plt.suptitle('Batch Normalization 효과', y=1.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md3",
   "metadata": {},
   "source": [
    "### 1-3. 정규화 기법 조합 비교 — MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier(use_dropout=False, use_bn=False, p_drop=0.3):\n",
    "    \"\"\"정규화 조합별 MNIST 분류기 생성\"\"\"\n",
    "    layers = []\n",
    "    in_dim = 784\n",
    "    for out_dim in [256, 128, 64]:\n",
    "        layers.append(nn.Linear(in_dim, out_dim))\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        if use_dropout:\n",
    "            layers.append(nn.Dropout(p=p_drop))\n",
    "        in_dim = out_dim\n",
    "    layers.append(nn.Linear(in_dim, 10))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def train_model(model, epochs=30, lr=0.001):\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    tr_losses, te_accs = [], []\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            epoch_loss += loss.item() * len(xb)\n",
    "        tr_losses.append(epoch_loss / len(train_loader.dataset))\n",
    "        _, te_acc = evaluate(model, test_loader)\n",
    "        te_accs.append(te_acc)\n",
    "    return tr_losses, te_accs\n",
    "\n",
    "configs = [\n",
    "    ('기본 (정규화 없음)',    dict(use_dropout=False, use_bn=False)),\n",
    "    ('Dropout (p=0.3)',       dict(use_dropout=True,  use_bn=False, p_drop=0.3)),\n",
    "    ('BatchNorm',             dict(use_dropout=False, use_bn=True)),\n",
    "    ('Dropout + BatchNorm',   dict(use_dropout=True,  use_bn=True,  p_drop=0.3)),\n",
    "]\n",
    "colors_cfg = ['gray', 'tomato', 'steelblue', 'seagreen']\n",
    "\n",
    "all_results = {}\n",
    "for name, cfg in configs:\n",
    "    torch.manual_seed(42)\n",
    "    m = make_classifier(**cfg)\n",
    "    tr_l, te_a = train_model(m, epochs=30)\n",
    "    all_results[name] = dict(model=m, tr_losses=tr_l, te_accs=te_a)\n",
    "    print(f'{name:<25} 최종 Test Acc: {te_a[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "for (name, res), color in zip(all_results.items(), colors_cfg):\n",
    "    axes[0].plot(res['tr_losses'], color=color, lw=2, label=name)\n",
    "    axes[1].plot(res['te_accs'],   color=color, lw=2, label=name)\n",
    "\n",
    "axes[0].set_title('학습 손실 비교')\n",
    "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Train Loss')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "axes[1].set_title('Test Accuracy 비교')\n",
    "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Test Accuracy')\n",
    "axes[1].set_ylim(0.7, 1.0)\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('정규화 기법 조합별 MNIST 학습 비교', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 과적합 정도 측정: 마지막 에폭 Train Loss vs Test Loss\n",
    "print(f'{'방법':<25} {'Train Loss':>12} {'Test Acc':>10}')\n",
    "print('-' * 50)\n",
    "for name, res in all_results.items():\n",
    "    _, tr_acc = evaluate(res['model'], train_loader)\n",
    "    _, te_acc = evaluate(res['model'], test_loader)\n",
    "    gap = tr_acc - te_acc\n",
    "    print(f'{name:<25} {res[\"tr_losses\"][-1]:>12.4f} {te_acc:>10.4f}  (Train-Test Gap={gap:+.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2. 클래스 불균형 처리\n",
    "\n",
    "### 2-1. 불균형 데이터의 문제\n",
    "\n",
    "실제 데이터는 클래스 간 샘플 수 차이가 큰 경우가 많습니다:\n",
    "- 의료: 정상 95% vs 질환 5%\n",
    "- 금융: 정상 거래 99% vs 사기 1%\n",
    "\n",
    "**정확도 역설 (Accuracy Paradox):**  \n",
    "소수 클래스를 무조건 다수 클래스로 예측해도 높은 정확도!\n",
    "\n",
    "$$\\text{Acc} = \\frac{9500}{10000} = 95\\% \\quad (\\text{하지만 질환을 하나도 못 찾음})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불균형 MNIST 데이터 생성 (클래스 0~4: 전체, 클래스 5~9: 10%만)\n",
    "def make_imbalanced(X, y, minority_ratio=0.1, minority_classes=None):\n",
    "    if minority_classes is None:\n",
    "        minority_classes = list(range(5, 10))\n",
    "    keep_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "    for c in range(10):\n",
    "        idx = (y == c).nonzero(as_tuple=True)[0]\n",
    "        if c in minority_classes:\n",
    "            n_keep = max(1, int(len(idx) * minority_ratio))\n",
    "            perm   = torch.randperm(len(idx))[:n_keep]\n",
    "            keep_mask[idx[perm]] = True\n",
    "        else:\n",
    "            keep_mask[idx] = True\n",
    "    return X[keep_mask], y[keep_mask]\n",
    "\n",
    "torch.manual_seed(0)\n",
    "X_imb, y_imb = make_imbalanced(X_mn_tr, y_mn_tr, minority_ratio=0.1)\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "counts_balanced   = torch.bincount(y_mn_tr)\n",
    "counts_imbalanced = torch.bincount(y_imb)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 3.5))\n",
    "x_pos = np.arange(10)\n",
    "colors_bal = ['steelblue']*5 + ['tomato']*5\n",
    "axes[0].bar(x_pos, counts_balanced.numpy(), color='steelblue', edgecolor='k', alpha=0.85)\n",
    "axes[0].set_title('균형 데이터 — 클래스별 샘플 수')\n",
    "axes[0].set_xlabel('숫자 클래스'); axes[0].set_ylabel('샘플 수')\n",
    "for i, v in enumerate(counts_balanced):\n",
    "    axes[0].text(i, v+5, str(v.item()), ha='center', fontsize=8)\n",
    "\n",
    "axes[1].bar(x_pos, counts_imbalanced.numpy(), color=colors_bal, edgecolor='k', alpha=0.85)\n",
    "axes[1].set_title('불균형 데이터 — 클래스 5~9가 10%')\n",
    "axes[1].set_xlabel('숫자 클래스'); axes[1].set_ylabel('샘플 수')\n",
    "for i, v in enumerate(counts_imbalanced):\n",
    "    axes[1].text(i, v+2, str(v.item()), ha='center', fontsize=8)\n",
    "handles = [plt.Rectangle((0,0),1,1, color='steelblue'), plt.Rectangle((0,0),1,1, color='tomato')]\n",
    "axes[1].legend(handles, ['다수 클래스(0~4)', '소수 클래스(5~9)'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'균형 데이터   총 {len(y_mn_tr)}개, 클래스당 ~{len(y_mn_tr)//10}개')\n",
    "print(f'불균형 데이터 총 {len(y_imb)}개, 0~4: ~{counts_imbalanced[:5].float().mean():.0f}개, '\n",
    "      f'5~9: ~{counts_imbalanced[5:].float().mean():.0f}개')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md2",
   "metadata": {},
   "source": [
    "### 2-2. 해결책 비교\n",
    "\n",
    "| 방법 | 원리 | 특징 |\n",
    "|---|---|---|\n",
    "| **기본 (처리 없음)** | 그대로 학습 | 소수 클래스 무시 |\n",
    "| **Weighted Loss** | 소수 클래스 손실에 가중치 | 구현 쉬움, 안정적 |\n",
    "| **WeightedRandomSampler** | 소수 클래스를 더 자주 샘플링 | 에폭당 다양성↑ |\n",
    "\n",
    "**클래스 가중치 계산:**  \n",
    "$$w_c = \\frac{N}{K \\cdot n_c}$$\n",
    "- $N$: 전체 샘플, $K$: 클래스 수, $n_c$: 클래스 $c$의 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 가중치 계산\n",
    "N, K = len(y_imb), 10\n",
    "class_weights = torch.tensor(\n",
    "    [N / (K * counts_imbalanced[c].item()) for c in range(10)],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "print('클래스 가중치:')\n",
    "for c, w in enumerate(class_weights):\n",
    "    print(f'  클래스 {c}: {w:.3f}')\n",
    "\n",
    "# WeightedRandomSampler용 샘플 가중치\n",
    "sample_weights = class_weights[y_imb]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(y_imb), replacement=True)\n",
    "\n",
    "# 데이터로더 3가지\n",
    "loader_plain  = make_loader(X_imb, y_imb)\n",
    "loader_sampler= make_loader(X_imb, y_imb, shuffle=False, sampler=sampler)\n",
    "\n",
    "# Weighted Loss 모델 학습\n",
    "crit_weighted = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "def train_imb(loader, use_weighted_loss=False, epochs=25):\n",
    "    torch.manual_seed(42)\n",
    "    model = make_classifier(use_dropout=True, use_bn=True)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    crit  = crit_weighted if use_weighted_loss else nn.CrossEntropyLoss()\n",
    "    te_accs, te_f1s = [], []\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in loader:\n",
    "            opt.zero_grad()\n",
    "            loss = crit(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_mn_te).argmax(1).numpy()\n",
    "        te_accs.append(accuracy_score(y_mn_te.numpy(), preds))\n",
    "        te_f1s.append(f1_score(y_mn_te.numpy(), preds, average='macro'))\n",
    "    return model, te_accs, te_f1s\n",
    "\n",
    "print('\\n모델 학습 중...')\n",
    "m_plain,   acc_plain,   f1_plain   = train_imb(loader_plain,   use_weighted_loss=False)\n",
    "m_wloss,   acc_wloss,   f1_wloss   = train_imb(loader_plain,   use_weighted_loss=True)\n",
    "m_sampler, acc_sampler, f1_sampler = train_imb(loader_sampler, use_weighted_loss=False)\n",
    "print('완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "labels_m = ['기본 (처리 없음)', 'Weighted Loss', 'WeightedSampler']\n",
    "colors_m = ['gray', 'tomato', 'steelblue']\n",
    "\n",
    "for (label, accs, f1s), color in zip(\n",
    "    [(labels_m[0], acc_plain, f1_plain),\n",
    "     (labels_m[1], acc_wloss, f1_wloss),\n",
    "     (labels_m[2], acc_sampler, f1_sampler)], colors_m):\n",
    "    axes[0].plot(accs, color=color, lw=2, label=label)\n",
    "    axes[1].plot(f1s,  color=color, lw=2, label=label)\n",
    "\n",
    "axes[0].set_title('Test Accuracy — 불균형 데이터')\n",
    "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim(0.5, 1.0); axes[0].legend(fontsize=9)\n",
    "\n",
    "axes[1].set_title('Test Macro F1 — 불균형 데이터')\n",
    "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Macro F1')\n",
    "axes[1].set_ylim(0.3, 1.0); axes[1].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('클래스 불균형 처리 방법 비교', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 F1 비교\n",
    "print(f'\\n{'방법':<20} {'Acc':>8} {'MacroF1':>10}')\n",
    "print('-' * 42)\n",
    "for label, m in zip(labels_m, [m_plain, m_wloss, m_sampler]):\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = m(X_mn_te).argmax(1).numpy()\n",
    "    acc = accuracy_score(y_mn_te.numpy(), preds)\n",
    "    f1  = f1_score(y_mn_te.numpy(), preds, average='macro')\n",
    "    f1s_per = f1_score(y_mn_te.numpy(), preds, average=None)\n",
    "    print(f'{label:<20} {acc:>8.4f} {f1:>10.4f}')\n",
    "    print(f'  클래스별 F1: {[f\"{v:.2f}\" for v in f1s_per]}')\n",
    "\n",
    "print('\\n→ Accuracy만 보면 \"기본\"이 좋아 보이지만, Macro F1은 소수 클래스 성능을 반영!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3. 학습률 스케줄러와 조기 종료\n",
    "\n",
    "### 3-1. 학습률 스케줄러 종류\n",
    "\n",
    "| 스케줄러 | 동작 | 특징 |\n",
    "|---|---|---|\n",
    "| **StepLR** | N 에폭마다 γ배 감소 | 간단, 예측 가능 |\n",
    "| **CosineAnnealingLR** | 코사인 곡선으로 감소 | 부드러운 감소, 최종 lr=0 |\n",
    "| **ReduceLROnPlateau** | 검증 손실 정체 시 감소 | 자동 적응, 실무 많이 사용 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 스케줄 시각화\n",
    "dummy_model = nn.Linear(1, 1)\n",
    "EPOCHS_VIZ  = 60\n",
    "LR_INIT     = 0.1\n",
    "\n",
    "schedulers = {\n",
    "    'StepLR (step=15, γ=0.5)': lambda opt: torch.optim.lr_scheduler.StepLR(\n",
    "        opt, step_size=15, gamma=0.5),\n",
    "    'CosineAnnealingLR (T=60)': lambda opt: torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        opt, T_max=EPOCHS_VIZ, eta_min=1e-4),\n",
    "    'CosineAnnealingWarmRestarts': lambda opt: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        opt, T_0=20, T_mult=1, eta_min=1e-4),\n",
    "    'ExponentialLR (γ=0.95)': lambda opt: torch.optim.lr_scheduler.ExponentialLR(\n",
    "        opt, gamma=0.95),\n",
    "}\n",
    "colors_sch = ['steelblue', 'tomato', 'seagreen', 'purple']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "for (name, sched_fn), color in zip(schedulers.items(), colors_sch):\n",
    "    opt  = torch.optim.SGD(dummy_model.parameters(), lr=LR_INIT)\n",
    "    sch  = sched_fn(opt)\n",
    "    lrs  = []\n",
    "    for _ in range(EPOCHS_VIZ):\n",
    "        lrs.append(opt.param_groups[0]['lr'])\n",
    "        opt.step()\n",
    "        sch.step()\n",
    "    ax.plot(lrs, color=color, lw=2.5, label=name)\n",
    "\n",
    "ax.set_title('학습률 스케줄러 비교 (초기 lr=0.1)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md2",
   "metadata": {},
   "source": [
    "### 3-2. 조기 종료 (Early Stopping)\n",
    "\n",
    "검증 손실이 일정 에폭 동안 개선되지 않으면 학습을 중단합니다:\n",
    "\n",
    "```\n",
    "best_val_loss = ∞\n",
    "patience = 10    ← 몇 에폭 더 기다릴지\n",
    "counter  = 0\n",
    "\n",
    "for each epoch:\n",
    "    val_loss = validate()\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        save_best_model()\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            stop training\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"검증 손실 기반 조기 종료\"\"\"\n",
    "    def __init__(self, patience=10, min_delta=1e-4):\n",
    "        self.patience   = patience\n",
    "        self.min_delta  = min_delta\n",
    "        self.counter    = 0\n",
    "        self.best_loss  = float('inf')\n",
    "        self.best_state = None\n",
    "        self.stopped_at = None\n",
    "\n",
    "    def step(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss  = val_loss\n",
    "            self.counter    = 0\n",
    "            self.best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            return False   # 계속 학습\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            return self.counter >= self.patience   # True = 종료\n",
    "\n",
    "    def restore(self, model):\n",
    "        if self.best_state:\n",
    "            model.load_state_dict(self.best_state)\n",
    "\n",
    "\n",
    "# 조기 종료 + 스케줄러 조합 학습\n",
    "torch.manual_seed(42)\n",
    "model_es   = make_classifier(use_dropout=True, use_bn=True)\n",
    "opt_es     = torch.optim.Adam(model_es.parameters(), lr=0.005)\n",
    "sched_es   = torch.optim.lr_scheduler.CosineAnnealingLR(opt_es, T_max=100, eta_min=1e-5)\n",
    "crit_es    = nn.CrossEntropyLoss()\n",
    "stopper    = EarlyStopping(patience=12)\n",
    "\n",
    "# 검증용 로더 (Train의 20%)\n",
    "n_val   = int(len(X_mn_tr) * 0.2)\n",
    "X_val_e = X_mn_tr[-n_val:];  y_val_e = y_mn_tr[-n_val:]\n",
    "X_tr_e  = X_mn_tr[:-n_val];  y_tr_e  = y_mn_tr[:-n_val]\n",
    "val_loader_e  = make_loader(X_val_e, y_val_e, shuffle=False)\n",
    "train_loader_e= make_loader(X_tr_e,  y_tr_e)\n",
    "\n",
    "tr_losses_es, val_losses_es, lrs_es = [], [], []\n",
    "stopped_epoch = None\n",
    "\n",
    "for epoch in range(1, 150):\n",
    "    # 학습\n",
    "    model_es.train()\n",
    "    ep_loss = 0\n",
    "    for xb, yb in train_loader_e:\n",
    "        opt_es.zero_grad()\n",
    "        loss = crit_es(model_es(xb), yb)\n",
    "        loss.backward()\n",
    "        opt_es.step()\n",
    "        ep_loss += loss.item() * len(xb)\n",
    "    tr_losses_es.append(ep_loss / len(train_loader_e.dataset))\n",
    "\n",
    "    # 검증\n",
    "    val_loss, _ = evaluate(model_es, val_loader_e)\n",
    "    val_losses_es.append(val_loss)\n",
    "    lrs_es.append(opt_es.param_groups[0]['lr'])\n",
    "\n",
    "    sched_es.step()\n",
    "    if stopper.step(val_loss, model_es):\n",
    "        stopped_epoch = epoch\n",
    "        break\n",
    "\n",
    "stopper.restore(model_es)   # 최적 가중치 복원\n",
    "\n",
    "_, final_acc = evaluate(model_es, test_loader)\n",
    "print(f'조기 종료: epoch {stopped_epoch} (best_val_loss={stopper.best_loss:.4f})')\n",
    "print(f'최적 가중치 복원 후 Test Acc: {final_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "epochs_range = list(range(1, len(tr_losses_es) + 1))\n",
    "axes[0].plot(epochs_range, tr_losses_es,  color='steelblue', lw=2, label='Train Loss')\n",
    "axes[0].plot(epochs_range, val_losses_es, color='tomato',    lw=2, label='Val Loss')\n",
    "if stopped_epoch:\n",
    "    best_e = np.argmin(val_losses_es) + 1\n",
    "    axes[0].axvline(best_e,      color='seagreen', lw=2, linestyle='--',\n",
    "                    label=f'최적 에폭={best_e}')\n",
    "    axes[0].axvline(stopped_epoch, color='gray',   lw=2, linestyle=':',\n",
    "                    label=f'종료 에폭={stopped_epoch}')\n",
    "axes[0].set_title('조기 종료 학습 곡선')\n",
    "axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "axes[1].plot(epochs_range, lrs_es, color='purple', lw=2)\n",
    "axes[1].set_title('CosineAnnealingLR 학습률 변화')\n",
    "axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Learning Rate')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.suptitle('CosineAnnealingLR + EarlyStopping 조합', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p4-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4. 다중 클래스 ROC · Label Smoothing\n",
    "\n",
    "### 4-1. 다중 클래스 ROC (One-vs-Rest)\n",
    "\n",
    "이진 ROC를 다중 클래스로 확장하는 **OvR (One-vs-Rest)** 전략:\n",
    "\n",
    "$$\\text{클래스 } k \\text{ ROC} = \\text{class } k \\text{ vs 나머지 전체를 이진 문제로}$$\n",
    "\n",
    "- **Macro AUC**: 클래스별 AUC 단순 평균 → 클래스 불균형 반영 안 함\n",
    "- **Weighted AUC**: 샘플 수 기반 가중 평균 → 실제 분포 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 서브셋 (0~4 클래스만, 시각화 단순화)\n",
    "mask_5 = y_mn_te < 5\n",
    "X_5 = X_mn_te[mask_5]\n",
    "y_5 = y_mn_te[mask_5]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_roc = make_classifier(use_dropout=True, use_bn=True)\n",
    "\n",
    "# 5-클래스 분류기로 재학습\n",
    "mask_5_tr = y_mn_tr < 5\n",
    "X_5_tr, y_5_tr = X_mn_tr[mask_5_tr], y_mn_tr[mask_5_tr]\n",
    "\n",
    "# 출력 뉴런 5개로 교체\n",
    "model_roc5 = nn.Sequential(\n",
    "    nn.Linear(784, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.3),\n",
    "    nn.Linear(128, 5)\n",
    ")\n",
    "opt_roc = torch.optim.Adam(model_roc5.parameters(), lr=0.001)\n",
    "for _ in range(20):\n",
    "    model_roc5.train()\n",
    "    for xb, yb in make_loader(X_5_tr, y_5_tr):\n",
    "        opt_roc.zero_grad()\n",
    "        loss = nn.CrossEntropyLoss()(model_roc5(xb), yb)\n",
    "        loss.backward()\n",
    "        opt_roc.step()\n",
    "\n",
    "model_roc5.eval()\n",
    "with torch.no_grad():\n",
    "    probs_5 = F.softmax(model_roc5(X_5), dim=1).numpy()\n",
    "y_5_np = y_5.numpy()\n",
    "\n",
    "# OvR ROC 곡선\n",
    "y_5_bin = label_binarize(y_5_np, classes=list(range(5)))\n",
    "colors_roc = ['steelblue', 'tomato', 'seagreen', 'purple', 'orange']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "auc_per_class = []\n",
    "for c, color in enumerate(colors_roc):\n",
    "    fpr, tpr, _ = roc_curve(y_5_bin[:, c], probs_5[:, c])\n",
    "    auc_c = roc_auc_score(y_5_bin[:, c], probs_5[:, c])\n",
    "    auc_per_class.append(auc_c)\n",
    "    axes[0].plot(fpr, tpr, color=color, lw=2, label=f'클래스 {c} (AUC={auc_c:.3f})')\n",
    "\n",
    "axes[0].plot([0,1],[0,1], 'k--', lw=1.5, label='랜덤 (AUC=0.5)')\n",
    "axes[0].set_title('OvR ROC 곡선 — 클래스 0~4')\n",
    "axes[0].set_xlabel('FPR'); axes[0].set_ylabel('TPR')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "macro_auc    = np.mean(auc_per_class)\n",
    "weighted_auc = roc_auc_score(y_5_bin, probs_5, average='weighted', multi_class='ovr')\n",
    "\n",
    "bars = axes[1].bar(range(5), auc_per_class, color=colors_roc, edgecolor='k', alpha=0.85)\n",
    "axes[1].axhline(macro_auc,    color='black',  lw=2, linestyle='--',\n",
    "                label=f'Macro AUC={macro_auc:.3f}')\n",
    "axes[1].axhline(weighted_auc, color='gray',   lw=2, linestyle=':',\n",
    "                label=f'Weighted AUC={weighted_auc:.3f}')\n",
    "for bar, v in zip(bars, auc_per_class):\n",
    "    axes[1].text(bar.get_x()+bar.get_width()/2, v+0.003, f'{v:.3f}', ha='center', fontsize=9)\n",
    "axes[1].set_xticks(range(5)); axes[1].set_xticklabels([f'클래스 {i}' for i in range(5)])\n",
    "axes[1].set_title('클래스별 AUC')\n",
    "axes[1].set_ylim(0.9, 1.01)\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p4-md2",
   "metadata": {},
   "source": [
    "### 4-2. Label Smoothing\n",
    "\n",
    "**Label Smoothing**은 원-핫 레이블을 부드럽게 만들어 **과신뢰(overconfidence)** 를 방지합니다:\n",
    "\n",
    "$$y_{\\text{smooth}} = (1-\\epsilon)\\cdot y_{\\text{one-hot}} + \\frac{\\epsilon}{K}$$\n",
    "\n",
    "- $\\epsilon = 0.1$이면: 정답 클래스 확률 목표 = $0.9 + 0.01 = 0.91$, 나머지 = $0.01$\n",
    "- 모델이 **\"완전히 확신\"** 하는 대신 약간의 불확실성을 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing 효과 시각화\n",
    "K = 10\n",
    "epsilons = [0.0, 0.05, 0.1, 0.2]\n",
    "target_class = 3\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "for ax, eps in zip(axes, epsilons):\n",
    "    y_smooth = np.full(K, eps / K)\n",
    "    y_smooth[target_class] += (1 - eps)\n",
    "    bars = ax.bar(range(K), y_smooth,\n",
    "                  color=['tomato' if i == target_class else 'steelblue' for i in range(K)],\n",
    "                  edgecolor='k', alpha=0.85)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_title(f'ε={eps}\\n정답 클래스 목표={y_smooth[target_class]:.2f}')\n",
    "    ax.set_xticks(range(K))\n",
    "    ax.set_xlabel('클래스')\n",
    "    if eps == 0: ax.set_ylabel('레이블 값')\n",
    "plt.suptitle(f'Label Smoothing — 정답 클래스={target_class} (빨강)', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PyTorch CrossEntropyLoss에 label_smoothing 파라미터 내장\n",
    "logits_demo = torch.tensor([[5.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]])\n",
    "target_demo = torch.tensor([0])\n",
    "print(f'Softmax 확률: {F.softmax(logits_demo, dim=1).detach().numpy().round(3)}')\n",
    "for eps in [0.0, 0.1, 0.2]:\n",
    "    loss = nn.CrossEntropyLoss(label_smoothing=eps)(logits_demo, target_demo)\n",
    "    print(f'  label_smoothing={eps:.1f}: Loss={loss.item():.4f}')\n",
    "print('→ Label Smoothing이 클수록 과신뢰 모델의 손실이 더 높아짐 (페널티)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Smoothing 유무 학습 비교\n",
    "def train_with_ls(label_smoothing, epochs=25):\n",
    "    torch.manual_seed(42)\n",
    "    m    = make_classifier(use_dropout=True, use_bn=True)\n",
    "    opt  = torch.optim.Adam(m.parameters(), lr=0.001)\n",
    "    crit = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "    te_accs = []\n",
    "    for _ in range(epochs):\n",
    "        m.train()\n",
    "        for xb, yb in train_loader:\n",
    "            opt.zero_grad()\n",
    "            crit(m(xb), yb).backward()\n",
    "            opt.step()\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = m(X_mn_te).argmax(1)\n",
    "        te_accs.append((preds == y_mn_te).float().mean().item())\n",
    "    # 최종 예측 확신도 (정답 클래스 확률 평균)\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        probs_all = F.softmax(m(X_mn_te), dim=1)\n",
    "    confidence = probs_all.max(1).values.mean().item()\n",
    "    return m, te_accs, confidence\n",
    "\n",
    "ls_results = {}\n",
    "for eps in [0.0, 0.1, 0.2]:\n",
    "    m, accs, conf = train_with_ls(eps)\n",
    "    ls_results[eps] = dict(model=m, accs=accs, confidence=conf)\n",
    "    print(f'label_smoothing={eps:.1f}: 최종 Test Acc={accs[-1]:.4f}, 평균 확신도={conf:.4f}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "colors_ls = ['steelblue', 'tomato', 'seagreen']\n",
    "for (eps, res), color in zip(ls_results.items(), colors_ls):\n",
    "    axes[0].plot(res['accs'], color=color, lw=2, label=f'ε={eps}')\n",
    "axes[0].set_title('Label Smoothing별 Test Accuracy'); axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy'); axes[0].legend()\n",
    "\n",
    "confs = [res['confidence'] for res in ls_results.values()]\n",
    "axes[1].bar([f'ε={e}' for e in ls_results.keys()], confs,\n",
    "            color=colors_ls, edgecolor='k', alpha=0.85)\n",
    "for i, v in enumerate(confs):\n",
    "    axes[1].text(i, v+0.003, f'{v:.4f}', ha='center')\n",
    "axes[1].set_title('평균 예측 확신도\\n(낮을수록 과신뢰 적음)')\n",
    "axes[1].set_ylim(0.8, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise\n",
    "\n",
    "### Exercise 1. Dropout 비율 체계적 실험\n",
    "\n",
    "Dropout 비율 `p = 0.0, 0.1, 0.3, 0.5, 0.7`에 대해 MNIST 분류기를 각각 학습하고:  \n",
    "1. Train Accuracy vs Test Accuracy 갭 (= 과적합 정도) 을 그래프로 시각화하세요.  \n",
    "2. 리프 수 대신 **파라미터 수는 동일**하게 유지하면서 최적 Dropout 비율을 찾으세요.  \n",
    "3. 어느 비율에서 Train-Test 갭이 가장 작으면서 Test Acc가 가장 높은지 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Dropout 비율 실험\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md2",
   "metadata": {},
   "source": [
    "### Exercise 2. 불균형 MNIST — 두 가지 전략 성능 분석\n",
    "\n",
    "클래스 0~4는 전체, 클래스 5~9는 **5%만** 사용하는 더 심한 불균형 상황에서:  \n",
    "1. **Weighted CrossEntropyLoss** 와 **WeightedRandomSampler** 두 전략을 비교하세요.\n",
    "2. 단순 Accuracy 외에 **클래스별 Precision / Recall**도 함께 출력하세요.  \n",
    "3. 소수 클래스(5~9)에 대한 **Macro Recall** 기준 어떤 방법이 더 효과적인지 분석하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: 심한 불균형 (5%) 처리 비교\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md3",
   "metadata": {},
   "source": [
    "### Exercise 3. (도전) ReduceLROnPlateau + EarlyStopping 파이프라인\n",
    "\n",
    "다음 조건으로 학습 파이프라인을 완성하세요:\n",
    "- 모델: `784 → 512 → 256 → 128 → 10` + BatchNorm + Dropout(p=0.4)\n",
    "- 옵티마이저: `Adam`, 초기 lr=0.003\n",
    "- 스케줄러: `ReduceLROnPlateau(mode='min', factor=0.5, patience=5)`\n",
    "- 조기 종료: `patience=15`\n",
    "- 학습 곡선(train/val loss)과 학습률 변화를 **하나의 그래프**에 겹쳐 시각화  \n",
    "  (y축 왼쪽=Loss, y축 오른쪽=LR)\n",
    "- 최종 Test Accuracy와 조기 종료된 에폭을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: ReduceLROnPlateau + EarlyStopping\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| 개념 | 핵심 내용 |\n",
    "|---|---|\n",
    "| **Dropout** | 학습 중 뉴런 무작위 비활성화 → `model.train()` / `model.eval()` 구분 필수 |\n",
    "| **BatchNorm** | 배치 내 활성화 정규화 → 학습 안정화, 빠른 수렴 |\n",
    "| **Inverted Dropout** | train 시 $1/(1-p)$ 스케일링으로 eval 기댓값 보존 |\n",
    "| **클래스 불균형** | Accuracy 역설 주의 — Macro F1 / Recall로 평가 |\n",
    "| **Weighted Loss** | $w_c = N/(K \\cdot n_c)$ — 소수 클래스 손실 가중 |\n",
    "| **WeightedRandomSampler** | 소수 클래스 오버샘플링 — 에폭당 클래스 균형 유지 |\n",
    "| **StepLR** | 고정 주기로 lr 감소 |\n",
    "| **CosineAnnealing** | 코사인 곡선으로 부드럽게 lr 감소 |\n",
    "| **ReduceLROnPlateau** | 검증 손실 정체 시 자동 lr 감소 |\n",
    "| **Early Stopping** | 검증 손실 개선 없으면 학습 중단 + 최적 가중치 복원 |\n",
    "| **OvR ROC** | 다중 클래스를 이진 문제로 분해해 클래스별 AUC 계산 |\n",
    "| **Label Smoothing** | 원-핫 레이블 softening → 과신뢰 방지, 일반화↑ |\n",
    "\n",
    "---\n",
    "\n",
    "**다음 강의 (Week 7):** Tree-based Models — 결정 트리, 랜덤 포레스트, 앙상블"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
