{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 (Advanced) — Python for AI\n",
    "\n",
    "중급 내용을 충분히 이해한 상태에서, 실제 ML 프로젝트에서 자주 마주치는 **고급 Python 패턴**과 **사이킷런 파이프라인** 설계까지 다룹니다.\n",
    "\n",
    "**학습 목표:**\n",
    "1. Python 고급 패턴 — Generator, Decorator, Context Manager, `functools`\n",
    "2. NumPy 고급 — `einsum`, SVD, PCA from scratch, 메모리 효율\n",
    "3. Pandas 고급 — 메서드 체이닝, MultiIndex, Rolling 윈도우, 메모리 최적화\n",
    "4. ML 전처리 파이프라인 — `sklearn` Pipeline + 커스텀 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time, functools, warnings\n",
    "from typing import Callable, Iterator, Any\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"font.family\"] = \"AppleGothic\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "rng = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. Python 고급 패턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Generator — 메모리 효율적인 대용량 데이터 처리\n",
    "\n",
    "리스트는 모든 값을 메모리에 올리지만, Generator는 **하나씩 필요할 때 생성**합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# 메모리 비교\n",
    "list_obj = [x**2 for x in range(100_000)]\n",
    "gen_obj  = (x**2 for x in range(100_000))\n",
    "\n",
    "print(f\"List   크기: {sys.getsizeof(list_obj):>10,} bytes\")\n",
    "print(f\"Generator 크기: {sys.getsizeof(gen_obj):>10,} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data: np.ndarray, batch_size: int) -> Iterator[np.ndarray]:\n",
    "    \"\"\"대용량 배열을 배치 단위로 순회하는 Generator.\"\"\"\n",
    "    n = len(data)\n",
    "    for start in range(0, n, batch_size):\n",
    "        yield data[start : start + batch_size]\n",
    "\n",
    "\n",
    "dataset = rng.random((1000, 4))   # 1000개 샘플\n",
    "\n",
    "batch_means = []\n",
    "for i, batch in enumerate(batch_generator(dataset, batch_size=100)):\n",
    "    batch_means.append(batch.mean())\n",
    "\n",
    "print(f\"총 배치 수  : {len(batch_means)}\")\n",
    "print(f\"배치별 평균 : {[round(m, 4) for m in batch_means]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yield from — Generator 위임\n",
    "def read_chunks(arrays: list, chunk_size: int) -> Iterator[np.ndarray]:\n",
    "    for arr in arrays:\n",
    "        yield from batch_generator(arr, chunk_size)\n",
    "\n",
    "parts = [rng.random((200, 4)) for _ in range(3)]   # 3개 파일 시뮬레이션\n",
    "total_rows = sum(chunk.shape[0] for chunk in read_chunks(parts, 50))\n",
    "print(f\"총 처리 행 수: {total_rows}\")   # 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Decorator — 함수에 기능 덧붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func: Callable) -> Callable:\n",
    "    \"\"\"함수 실행 시간을 측정하는 Decorator.\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t0 = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        print(f\"[timer] {func.__name__} → {elapsed*1000:.2f} ms\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def retry(max_attempts: int = 3, exceptions: tuple = (Exception,)):\n",
    "    \"\"\"실패 시 최대 max_attempts회 재시도하는 Decorator 팩토리.\"\"\"\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(1, max_attempts + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except exceptions as e:\n",
    "                    print(f\"  attempt {attempt}/{max_attempts} failed: {e}\")\n",
    "                    if attempt == max_attempts:\n",
    "                        raise\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@timer\n",
    "def slow_matmul(n: int) -> float:\n",
    "    A = rng.random((n, n))\n",
    "    B = rng.random((n, n))\n",
    "    return (A @ B).sum()\n",
    "\n",
    "slow_matmul(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lru_cache — 메모이제이션 (반복 호출 캐싱)\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def fibonacci(n: int) -> int:\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci(n - 1) + fibonacci(n - 2)\n",
    "\n",
    "%timeit fibonacci(35)   # 두 번째 호출부터 캐시 적중"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3. Context Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer_block(label: str):\n",
    "    \"\"\"코드 블록의 실행 시간을 측정하는 Context Manager.\"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        elapsed = time.perf_counter() - t0\n",
    "        print(f\"[{label}] {elapsed*1000:.2f} ms\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def numpy_seed(seed: int):\n",
    "    \"\"\"블록 내부에서만 재현 가능한 랜덤 시드를 사용.\"\"\"\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        np.random.set_state(state)  # 블록 종료 후 원래 상태 복원\n",
    "\n",
    "\n",
    "with timer_block(\"행렬 생성\"):\n",
    "    X = rng.random((2000, 2000))\n",
    "\n",
    "with timer_block(\"행렬 곱\"):\n",
    "    _ = X @ X.T\n",
    "\n",
    "with numpy_seed(0):\n",
    "    a = np.random.rand(3)\n",
    "with numpy_seed(0):\n",
    "    b = np.random.rand(3)\n",
    "print(\"재현 확인:\", np.allclose(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-4. `functools.partial` — 함수 부분 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def clip_outliers(series: pd.Series, low_q: float, high_q: float) -> pd.Series:\n",
    "    lo = series.quantile(low_q)\n",
    "    hi = series.quantile(high_q)\n",
    "    return series.clip(lo, hi)\n",
    "\n",
    "# 자주 쓰는 설정을 미리 고정\n",
    "clip_iqr  = partial(clip_outliers, low_q=0.25, high_q=0.75)\n",
    "clip_5_95 = partial(clip_outliers, low_q=0.05, high_q=0.95)\n",
    "\n",
    "s = pd.Series(rng.standard_normal(200))\n",
    "print(f\"원본 범위  : [{s.min():.2f}, {s.max():.2f}]\")\n",
    "print(f\"IQR 클립   : [{clip_iqr(s).min():.2f}, {clip_iqr(s).max():.2f}]\")\n",
    "print(f\"5-95% 클립 : [{clip_5_95(s).min():.2f}, {clip_5_95(s).max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 1.** 아래 `memoize` 데코레이터를 완성하세요.  \n",
    "> `lru_cache`를 사용하지 않고 딕셔너리로 직접 캐시를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(func: Callable) -> Callable:\n",
    "    cache = {}\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args):\n",
    "        # Your code here\n",
    "        pass\n",
    "    return wrapper\n",
    "\n",
    "@memoize\n",
    "def fib(n: int) -> int:\n",
    "    if n < 2: return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(fib(10))   # 55\n",
    "print(fib(30))   # 832040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2. NumPy 고급"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. `einsum` — 유연한 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rng.random((3, 4))\n",
    "B = rng.random((4, 5))\n",
    "v = rng.random(4)\n",
    "\n",
    "# 행렬 곱 A @ B\n",
    "assert np.allclose(np.einsum(\"ij,jk->ik\", A, B), A @ B)\n",
    "print(\"행렬 곱      :\", np.einsum(\"ij,jk->ik\", A, B).shape)   # (3, 5)\n",
    "\n",
    "# 내적 (dot product)\n",
    "assert np.allclose(np.einsum(\"i,i->\", v, v), v @ v)\n",
    "\n",
    "# 전치 (transpose)\n",
    "assert np.allclose(np.einsum(\"ij->ji\", A), A.T)\n",
    "\n",
    "# 배치 행렬 곱 (batch matmul) — 3D 텐서\n",
    "batch_A = rng.random((8, 3, 4))\n",
    "batch_B = rng.random((8, 4, 5))\n",
    "result  = np.einsum(\"bij,bjk->bik\", batch_A, batch_B)\n",
    "print(\"배치 행렬 곱 :\", result.shape)   # (8, 3, 5)\n",
    "\n",
    "# Attention score (Q @ K^T) — Transformer의 핵심 연산\n",
    "Q = rng.random((8, 10, 64))  # (batch, seq, d_k)\n",
    "K = rng.random((8, 10, 64))\n",
    "scores = np.einsum(\"bid,bjd->bij\", Q, K)   # (batch, seq, seq)\n",
    "print(\"Attention score:\", scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. SVD & PCA from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "X_raw = digits.data.astype(float)   # (1797, 64)\n",
    "y     = digits.target\n",
    "print(\"데이터 형태:\", X_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA from scratch (SVD 기반)\n",
    "def pca_from_scratch(X: np.ndarray, n_components: int):\n",
    "    # 1. 중심화\n",
    "    mean = X.mean(axis=0)\n",
    "    X_c  = X - mean\n",
    "\n",
    "    # 2. SVD 분해: X = U @ S_diag @ Vt\n",
    "    U, S, Vt = np.linalg.svd(X_c, full_matrices=False)\n",
    "\n",
    "    # 3. 주성분 선택 (V의 처음 k열)\n",
    "    components = Vt[:n_components]            # (k, d)\n",
    "\n",
    "    # 4. 투영\n",
    "    X_pca = X_c @ components.T               # (n, k)\n",
    "\n",
    "    # 5. 분산 설명 비율\n",
    "    explained_var_ratio = (S**2 / (S**2).sum())[:n_components]\n",
    "\n",
    "    return X_pca, components, explained_var_ratio\n",
    "\n",
    "\n",
    "X_pca, components, var_ratio = pca_from_scratch(X_raw, n_components=2)\n",
    "print(f\"PC1 설명 분산: {var_ratio[0]*100:.1f}%\")\n",
    "print(f\"PC2 설명 분산: {var_ratio[1]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# PCA 산점도\n",
    "scatter = axes[0].scatter(X_pca[:, 0], X_pca[:, 1],\n",
    "                          c=y, cmap=\"tab10\", alpha=0.6, s=15)\n",
    "plt.colorbar(scatter, ax=axes[0], label=\"digit\")\n",
    "axes[0].set_title(\"PCA (2D) — Digits dataset\")\n",
    "axes[0].set_xlabel(f\"PC1 ({var_ratio[0]*100:.1f}%)\")\n",
    "axes[0].set_ylabel(f\"PC2 ({var_ratio[1]*100:.1f}%)\")\n",
    "\n",
    "# Scree Plot (성분 수 결정)\n",
    "_, _, all_var = pca_from_scratch(X_raw, n_components=30)\n",
    "cumvar = np.cumsum(all_var) * 100\n",
    "axes[1].plot(range(1, len(cumvar)+1), cumvar, marker=\"o\", markersize=4)\n",
    "axes[1].axhline(90, color=\"red\", linestyle=\"--\", label=\"90% 기준선\")\n",
    "axes[1].set_title(\"Scree Plot (누적 분산)\")\n",
    "axes[1].set_xlabel(\"주성분 수\")\n",
    "axes[1].set_ylabel(\"누적 분산 설명율 (%)\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 메모리 레이아웃과 효율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rng.random((1000, 1000))\n",
    "\n",
    "# C-order(행 우선) vs F-order(열 우선)\n",
    "A_c = np.ascontiguousarray(A)          # C-order\n",
    "A_f = np.asfortranarray(A)             # F-order\n",
    "\n",
    "with timer_block(\"행 합 (C-order)\"):  _ = A_c.sum(axis=1)\n",
    "with timer_block(\"행 합 (F-order)\"):  _ = A_f.sum(axis=1)\n",
    "\n",
    "with timer_block(\"열 합 (C-order)\"):  _ = A_c.sum(axis=0)\n",
    "with timer_block(\"열 합 (F-order)\"):  _ = A_f.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# float64 vs float32 — 메모리 절반, 속도 향상\n",
    "X64 = rng.random((5000, 5000)).astype(np.float64)\n",
    "X32 = X64.astype(np.float32)\n",
    "\n",
    "print(f\"float64 메모리: {X64.nbytes / 1e6:.0f} MB\")\n",
    "print(f\"float32 메모리: {X32.nbytes / 1e6:.0f} MB\")\n",
    "\n",
    "with timer_block(\"float64 합\"):  _ = X64.sum()\n",
    "with timer_block(\"float32 합\"):  _ = X32.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 2.** SVD를 이용한 **저차원 행렬 근사(Image Compression)**를 구현하세요.  \n",
    "> 임의의 (100×100) 행렬을 생성하고, 상위 k개 특이값만 사용해 재구성한 뒤  \n",
    "> k=5, 20, 50일 때 원본 대비 **재구성 오차(Frobenius norm)** 를 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3. Pandas 고급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 메서드 체이닝 + `pipe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_age(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"pclass · sex 그룹 중앙값으로 나이 결측 대체.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"age\"] = df.groupby([\"pclass\", \"sex\"])[\"age\"].transform(\n",
    "        lambda s: s.fillna(s.median())\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"family_size\"] = df[\"sibsp\"] + df[\"parch\"] + 1\n",
    "    df[\"is_alone\"]    = (df[\"family_size\"] == 1).astype(int)\n",
    "    df[\"log_fare\"]    = np.log1p(df[\"fare\"])\n",
    "    df[\"age_group\"]   = pd.cut(df[\"age\"],\n",
    "                               bins=[0, 12, 18, 60, 100],\n",
    "                               labels=[\"child\", \"teen\", \"adult\", \"senior\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "# 하나의 체인으로 전처리 파이프라인 구성\n",
    "df = (\n",
    "    titanic\n",
    "    .drop(columns=[\"deck\", \"embark_town\", \"alive\", \"who\", \"adult_male\", \"alone\"])\n",
    "    .drop_duplicates()\n",
    "    .pipe(fill_age)\n",
    "    .assign(embarked=lambda d: d[\"embarked\"].fillna(d[\"embarked\"].mode()[0]))\n",
    "    .pipe(add_features)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 집계 → MultiIndex 열 생성\n",
    "stats = (\n",
    "    df.groupby([\"pclass\", \"sex\"])\n",
    "    [[\"survived\", \"age\", \"fare\"]]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .round(2)\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiIndex 접근\n",
    "print(stats[(\"survived\", \"mean\")])           # 생존율\n",
    "print()\n",
    "print(stats.loc[(1, \"female\"), :])           # 1등석 여성\n",
    "\n",
    "# 열 평탄화 (flatten)\n",
    "stats.columns = [\"_\".join(col) for col in stats.columns]\n",
    "print(\"\\n평탄화 후:\", stats.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Rolling 윈도우 — 시계열 스타일 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 승객 번호 기준으로 rolling 통계 (시계열 아이디어를 표 데이터에 적용)\n",
    "df_sorted = df.sort_values(\"fare\").reset_index(drop=True)\n",
    "\n",
    "df_sorted[\"rolling_surv_mean\"]  = df_sorted[\"survived\"].rolling(window=30, min_periods=1).mean()\n",
    "df_sorted[\"expanding_surv_mean\"] = df_sorted[\"survived\"].expanding().mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(df_sorted[\"fare\"],               df_sorted[\"rolling_surv_mean\"],\n",
    "        label=\"Rolling(30)\", color=\"steelblue\")\n",
    "ax.plot(df_sorted[\"fare\"],               df_sorted[\"expanding_surv_mean\"],\n",
    "        label=\"Expanding\",   color=\"tomato\", linestyle=\"--\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_title(\"운임에 따른 생존율 (Rolling / Expanding)\")\n",
    "ax.set_xlabel(\"운임 (log scale)\")\n",
    "ax.set_ylabel(\"생존율\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. 메모리 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage_mb(df: pd.DataFrame) -> float:\n",
    "    return df.memory_usage(deep=True).sum() / 1e6\n",
    "\n",
    "print(f\"최적화 전: {memory_usage_mb(df):.3f} MB\")\n",
    "print(df.dtypes)\n",
    "\n",
    "def optimize_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(\"float64\").columns:\n",
    "        df[col] = df[col].astype(\"float32\")\n",
    "    for col in df.select_dtypes(\"int64\").columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    for col in df.select_dtypes(\"object\").columns:\n",
    "        if df[col].nunique() / len(df) < 0.5:   # 카디널리티 낮으면 category\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "df_opt = optimize_dtypes(df)\n",
    "print(f\"\\n최적화 후: {memory_usage_mb(df_opt):.3f} MB\")\n",
    "print(f\"절감율   : {(1 - memory_usage_mb(df_opt)/memory_usage_mb(df))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 3.** `df`에서 `pclass × age_group` 조합별로  \n",
    "> 생존율(`mean`), 인원수(`count`), 평균 운임(`fare mean`)을 계산하고  \n",
    "> 히트맵으로 **생존율**을 시각화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4. ML 전처리 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. 커스텀 sklearn Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"각 열을 quantile 기반으로 클리핑하는 Transformer.\"\"\"\n",
    "\n",
    "    def __init__(self, low_q: float = 0.05, high_q: float = 0.95):\n",
    "        self.low_q  = low_q\n",
    "        self.high_q = high_q\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.lowers_ = np.nanquantile(X, self.low_q, axis=0)\n",
    "        self.uppers_ = np.nanquantile(X, self.high_q, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        return np.clip(X, self.lowers_, self.uppers_)\n",
    "\n",
    "\n",
    "class TargetMeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"범주형 변수를 타겟 평균값으로 인코딩.\"\"\"\n",
    "\n",
    "    def __init__(self, smoothing: float = 1.0):\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X).ravel()\n",
    "        y = np.asarray(y)\n",
    "        self.global_mean_ = y.mean()\n",
    "        self.encoding_ = {}\n",
    "        for cat in np.unique(X):\n",
    "            mask = X == cat\n",
    "            n    = mask.sum()\n",
    "            cat_mean = y[mask].mean()\n",
    "            # Smoothed encoding\n",
    "            self.encoding_[cat] = (\n",
    "                (n * cat_mean + self.smoothing * self.global_mean_)\n",
    "                / (n + self.smoothing)\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.asarray(X).ravel()\n",
    "        return np.array([self.encoding_.get(v, self.global_mean_) for v in X]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# 동작 확인\n",
    "clipper = OutlierClipper()\n",
    "sample  = rng.standard_normal((100, 3))\n",
    "clipped = clipper.fit_transform(sample)\n",
    "print(\"원본 범위:\",  sample.min().round(2),  sample.max().round(2))\n",
    "print(\"클립 범위:\", clipped.min().round(2), clipped.max().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 완전한 ML 파이프라인 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose  import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute    import SimpleImputer\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics   import make_scorer, roc_auc_score\n",
    "\n",
    "# 특성 정의\n",
    "NUM_COLS = [\"age\", \"fare\", \"family_size\", \"log_fare\"]\n",
    "CAT_COLS = [\"sex\", \"embarked\"]\n",
    "ORD_COLS = [\"pclass\"]   # 순서가 있는 범주형\n",
    "\n",
    "# 수치형 파이프라인: 결측 대체 → 이상치 클리핑 → 표준화\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"clipper\", OutlierClipper(0.02, 0.98)),\n",
    "    (\"scaler\",  StandardScaler()),\n",
    "])\n",
    "\n",
    "# 범주형 파이프라인: 결측 대체 → 순서 인코딩\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "])\n",
    "\n",
    "# ColumnTransformer로 합치기\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipe, NUM_COLS),\n",
    "    (\"cat\", cat_pipe, CAT_COLS + ORD_COLS),\n",
    "])\n",
    "\n",
    "# 전체 파이프라인 (전처리 + 모델)\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\",        RandomForestClassifier(n_estimators=200, random_state=42)),\n",
    "])\n",
    "\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = NUM_COLS + CAT_COLS + ORD_COLS\n",
    "X = df[feature_cols]\n",
    "y = df[\"survived\"]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"roc_auc\":  \"roc_auc\",\n",
    "    \"f1\":       \"f1\",\n",
    "}\n",
    "\n",
    "with timer_block(\"5-Fold CV\"):\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Accuracy\": cv_results[\"test_accuracy\"],\n",
    "    \"ROC-AUC\":  cv_results[\"test_roc_auc\"],\n",
    "    \"F1\":       cv_results[\"test_f1\"],\n",
    "})\n",
    "\n",
    "print(results_df.round(4))\n",
    "print(\"\\n평균:\")\n",
    "print(results_df.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. 특성 중요도 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터로 학습 후 특성 중요도 추출\n",
    "pipeline.fit(X, y)\n",
    "rf_model    = pipeline.named_steps[\"model\"]\n",
    "feature_names = (\n",
    "    NUM_COLS\n",
    "    + CAT_COLS\n",
    "    + ORD_COLS\n",
    ")\n",
    "\n",
    "importances = pd.Series(rf_model.feature_importances_, index=feature_names)\n",
    "importances = importances.sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars = ax.barh(importances.index, importances.values,\n",
    "               color=plt.cm.RdYlGn(importances.values / importances.max()))\n",
    "ax.set_title(\"Random Forest 특성 중요도\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-5. 학습 곡선 (Learning Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    pipeline, X, y,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5, scoring=\"roc_auc\", n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std  = train_scores.std(axis=1)\n",
    "val_mean   = val_scores.mean(axis=1)\n",
    "val_std    = val_scores.std(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(train_sizes, train_mean, \"o-\", color=\"steelblue\", label=\"Train ROC-AUC\")\n",
    "ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"steelblue\")\n",
    "ax.plot(train_sizes, val_mean,   \"o-\", color=\"tomato\",   label=\"Val ROC-AUC\")\n",
    "ax.fill_between(train_sizes, val_mean - val_std,   val_mean + val_std,   alpha=0.2, color=\"tomato\")\n",
    "ax.set_title(\"Learning Curve (Random Forest)\")\n",
    "ax.set_xlabel(\"학습 샘플 수\")\n",
    "ax.set_ylabel(\"ROC-AUC\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise 4.** `TargetMeanEncoder`를 파이프라인에 적용해보세요.  \n",
    "> `sex`, `embarked` 열을 OrdinalEncoder 대신 `TargetMeanEncoder`로 교체하고  \n",
    "> 5-Fold CV ROC-AUC를 비교하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| 파트 | 핵심 개념 |\n",
    "|---|---|\n",
    "| Python 고급 | Generator(메모리 효율), Decorator(timer/retry/memoize), Context Manager, `functools.partial/lru_cache` |\n",
    "| NumPy 고급 | `einsum`(배치 연산/Attention), SVD/PCA from scratch, 메모리 레이아웃(C/F-order), float32 최적화 |\n",
    "| Pandas 고급 | 메서드 체이닝+`pipe()`, MultiIndex, Rolling/Expanding 윈도우, `category` dtype 메모리 최적화 |\n",
    "| ML 파이프라인 | 커스텀 Transformer(`OutlierClipper`, `TargetMeanEncoder`), `ColumnTransformer`, 5-Fold CV, Learning Curve |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
