{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c-title",
   "metadata": {},
   "source": [
    "# Lab 12 â€” Convolutional Neural Networks\n",
    "\n",
    "\n",
    "> **ì£¼ì œ:** í•©ì„±ê³± ì‹ ê²½ë§ â€” í•„í„°, í’€ë§, LeNet, VGG-style, CIFAR-10 ë¶„ë¥˜\n",
    "\n",
    "---\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "| # | ëª©í‘œ | ì˜ˆìƒ ì‹œê°„ |\n",
    "|---|---|---|\n",
    "| 1 | í•©ì„±ê³± ì—°ì‚°: í•„í„°, ìŠ¤íŠ¸ë¼ì´ë“œ, íŒ¨ë”©, íŠ¹ì„±ë§µ |  \n",
    "| 2 | CNN êµ¬í˜„ â€” LeNet-style, MLP vs CNN ë¹„êµ |  \n",
    "| 3 | ë” ê¹Šì€ CNN â€” VGG-style, BatchNorm |  \n",
    "| 4 | Exercise |  \n",
    "\n",
    "---\n",
    "\n",
    "**ë°ì´í„°ì…‹:** CIFAR-10 (PyTorch torchvision)  \n",
    "- 32Ã—32 RGB ì´ë¯¸ì§€, 10ê°œ í´ë˜ìŠ¤ (ë¹„í–‰ê¸°, ìë™ì°¨, ìƒˆ, ê³ ì–‘ì´, ì‚¬ìŠ´, ê°œ, ê°œêµ¬ë¦¬, ë§, ë°°, íŠ¸ëŸ­)  \n",
    "- Train 50,000ì¥ â†’ ì„œë¸Œì…‹ 10,000ì¥ (CPU í•™ìŠµ ì†ë„), Test 10,000ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "_fp = '/System/Library/Fonts/AppleGothic.ttf'\n",
    "fm.fontManager.addfont(_fp)\n",
    "plt.rcParams['font.family'] = fm.FontProperties(fname=_fp).get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ (MPS â†’ CUDA â†’ CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'Using device   : {device}')\n",
    "\n",
    "# CIFAR-10 ë¡œë“œ\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset_full = torchvision.datasets.CIFAR10('./data', train=True,  download=True, transform=transform)\n",
    "testset_full  = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# CPU í•™ìŠµì„ ìœ„í•´ train ì„œë¸Œì…‹ 10,000ì¥ ì‚¬ìš©\n",
    "torch.manual_seed(42)\n",
    "train_idx    = torch.randperm(len(trainset_full))[:10000].tolist()\n",
    "train_subset = Subset(trainset_full, train_idx)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64,  shuffle=True,  num_workers=0)\n",
    "test_loader  = DataLoader(testset_full,  batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('ë¹„í–‰ê¸°', 'ìë™ì°¨', 'ìƒˆ', 'ê³ ì–‘ì´', 'ì‚¬ìŠ´', 'ê°œ', 'ê°œêµ¬ë¦¬', 'ë§', 'ë°°', 'íŠ¸ëŸ­')\n",
    "\n",
    "print(f'\\nTrain (ì„œë¸Œì…‹) : {len(train_subset):,}ì¥')\n",
    "print(f'Test           : {len(testset_full):,}ì¥')\n",
    "print(f'í´ë˜ìŠ¤         : {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-data-vis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 ìƒ˜í”Œ ì‹œê°í™”\n",
    "def denorm(tensor):\n",
    "    \"\"\"ì •ê·œí™” í•´ì œ (0.5 mean, 0.5 std) â†’ [0, 1]\"\"\"\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3.5))\n",
    "shown = {c: 0 for c in range(10)}\n",
    "images_by_class = {c: [] for c in range(10)}\n",
    "\n",
    "for img, label in trainset_full:\n",
    "    if len(images_by_class[label]) < 2:\n",
    "        images_by_class[label].append(img)\n",
    "    if all(len(v) == 2 for v in images_by_class.values()):\n",
    "        break\n",
    "\n",
    "for c in range(10):\n",
    "    for row in range(2):\n",
    "        img = denorm(images_by_class[c][row]).permute(1, 2, 0).numpy()\n",
    "        axes[row, c].imshow(img)\n",
    "        if row == 0:\n",
    "            axes[row, c].set_title(classes[c], fontsize=9)\n",
    "        axes[row, c].axis('off')\n",
    "\n",
    "plt.suptitle('CIFAR-10 ìƒ˜í”Œ (í´ë˜ìŠ¤ë³„ 2ì¥, 32Ã—32 RGB)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì´ë¯¸ì§€ í˜•íƒœ í™•ì¸\n",
    "img, label = train_subset[0]\n",
    "print(f'ì´ë¯¸ì§€ shape: {img.shape}  (ì±„ë„, ë†’ì´, ë„ˆë¹„)')\n",
    "print(f'í”½ì…€ ë²”ìœ„   : [{img.min():.2f}, {img.max():.2f}]  (ì •ê·œí™” í›„)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. í•©ì„±ê³± ì—°ì‚° (Convolution Operation)\n",
    "\n",
    "### 1-1. í•„í„°(ì»¤ë„)ë€?\n",
    "\n",
    "í•©ì„±ê³±ì€ **ì‘ì€ í•„í„°(ì»¤ë„)**ê°€ ì´ë¯¸ì§€ ìœ„ë¥¼ ìŠ¬ë¼ì´ë”©í•˜ë©° ë‚´ì (dot product)ì„ ê³„ì‚°í•˜ëŠ” ì—°ì‚°ì…ë‹ˆë‹¤.\n",
    "\n",
    "$$\\text{output}[i, j] = \\sum_{m=0}^{K-1} \\sum_{n=0}^{K-1} \\text{input}[i \\cdot S + m,\\; j \\cdot S + n] \\times \\text{kernel}[m, n]$$\n",
    "\n",
    "| ìš©ì–´ | ì„¤ëª… |\n",
    "|---|---|\n",
    "| **í•„í„°/ì»¤ë„** | í•™ìŠµë˜ëŠ” ì‘ì€ ê°€ì¤‘ì¹˜ í–‰ë ¬ (e.g., 3Ã—3, 5Ã—5) |\n",
    "| **ìŠ¤íŠ¸ë¼ì´ë“œ S** | í•„í„°ê°€ í•œ ë²ˆì— ì´ë™í•˜ëŠ” í”½ì…€ ìˆ˜ |\n",
    "| **íŒ¨ë”© P** | ì´ë¯¸ì§€ ê°€ì¥ìë¦¬ì— ì¶”ê°€í•˜ëŠ” 0 í”½ì…€ |\n",
    "| **íŠ¹ì„±ë§µ** | conv ë ˆì´ì–´ì˜ ì¶œë ¥ (ê° í•„í„°ë§ˆë‹¤ í•˜ë‚˜ì”©) |\n",
    "\n",
    "**ì¶œë ¥ í¬ê¸° ê³µì‹:**\n",
    "$$H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} - K + 2P}{S} \\right\\rfloor + 1$$\n",
    "\n",
    "### 1-2. ë‹¤ì–‘í•œ í•„í„° íš¨ê³¼\n",
    "\n",
    "ìˆ˜ì‘ì—… í•„í„°ë¥¼ í†µí•´ CNNì´ í•™ìŠµí•˜ëŠ” íŠ¹ì„±(edge, texture ë“±)ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ì‘ì—… í•„í„° ì •ì˜ ë° ì‹œê°í™”\n",
    "import scipy.signal as signal\n",
    "\n",
    "# CIFAR-10 ì´ë¯¸ì§€ ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
    "img_tensor, lbl = trainset_full[3]\n",
    "img_rgb  = denorm(img_tensor).permute(1, 2, 0).numpy()          # (32,32,3)\n",
    "img_gray = img_rgb.mean(axis=2)                                   # (32,32)\n",
    "\n",
    "# ë‹¤ì–‘í•œ ìˆ˜ì‘ì—… í•„í„°\n",
    "filters = {\n",
    "    'Identity':           np.array([[0, 0, 0],\n",
    "                                    [0, 1, 0],\n",
    "                                    [0, 0, 0]], dtype=np.float32),\n",
    "    'Blur (í‰ê· )':        np.ones((3, 3), dtype=np.float32) / 9,\n",
    "    'Sharpen (ì„ ëª…í™”)':   np.array([[ 0,-1, 0],\n",
    "                                    [-1, 5,-1],\n",
    "                                    [ 0,-1, 0]], dtype=np.float32),\n",
    "    'Edge (ìˆ˜í‰)':        np.array([[-1,-2,-1],\n",
    "                                    [ 0, 0, 0],\n",
    "                                    [ 1, 2, 1]], dtype=np.float32),\n",
    "    'Edge (ìˆ˜ì§)':        np.array([[-1, 0, 1],\n",
    "                                    [-2, 0, 2],\n",
    "                                    [-1, 0, 1]], dtype=np.float32),\n",
    "    'Emboss (ì–‘ê°)':      np.array([[-2,-1, 0],\n",
    "                                    [-1, 1, 1],\n",
    "                                    [ 0, 1, 2]], dtype=np.float32),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(3, len(filters) + 1, figsize=(16, 7))\n",
    "\n",
    "# ì›ë³¸\n",
    "axes[0, 0].imshow(img_rgb);       axes[0, 0].set_title('ì›ë³¸ (RGB)', fontsize=9)\n",
    "axes[1, 0].imshow(img_gray, cmap='gray'); axes[1, 0].set_title('ê·¸ë ˆì´ìŠ¤ì¼€ì¼', fontsize=9)\n",
    "axes[2, 0].axis('off')\n",
    "for row in range(3): axes[row, 0].axis('off') if row == 2 else axes[row, 0].set_xticks([])\n",
    "\n",
    "for col, (name, kernel) in enumerate(filters.items(), start=1):\n",
    "    # í•„í„° ì‹œê°í™”\n",
    "    im = axes[0, col].imshow(kernel, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "    axes[0, col].set_title(name, fontsize=8)\n",
    "    for i in range(kernel.shape[0]):\n",
    "        for j in range(kernel.shape[1]):\n",
    "            axes[0, col].text(j, i, f'{kernel[i,j]:.0f}', ha='center', va='center', fontsize=8)\n",
    "    axes[0, col].set_xticks([]); axes[0, col].set_yticks([])\n",
    "\n",
    "    # í•„í„° ì ìš© ê²°ê³¼ (numpy conv)\n",
    "    result = signal.convolve2d(img_gray, kernel, mode='same', boundary='fill')\n",
    "    axes[1, col].imshow(result, cmap='gray')\n",
    "    axes[1, col].set_xticks([]); axes[1, col].set_yticks([])\n",
    "\n",
    "    # PyTorch Conv2dë¡œ ê²€ì¦\n",
    "    x_t = torch.tensor(img_gray[np.newaxis, np.newaxis], dtype=torch.float32)\n",
    "    k_t = torch.tensor(kernel[np.newaxis, np.newaxis], dtype=torch.float32)\n",
    "    result_pt = F.conv2d(x_t, k_t, padding=1)[0, 0].numpy()\n",
    "    axes[2, col].imshow(result_pt, cmap='gray')\n",
    "    axes[2, col].set_xlabel('PyTorch ê²€ì¦', fontsize=7)\n",
    "    axes[2, col].set_xticks([]); axes[2, col].set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel('í•„í„° (3Ã—3)', fontsize=9)\n",
    "axes[1, 0].set_ylabel('ì ìš© ê²°ê³¼', fontsize=9)\n",
    "axes[2, 0].set_ylabel('F.conv2d', fontsize=9)\n",
    "axes[2, 0].set_xticks([]); axes[2, 0].set_yticks([])\n",
    "\n",
    "plt.suptitle(f'ë‹¤ì–‘í•œ í•„í„° íš¨ê³¼ â€” í´ë˜ìŠ¤: {classes[lbl]}', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ğŸ“Œ í•µì‹¬: CNNì€ ì´ëŸ¬í•œ í•„í„°ë¥¼ ë°ì´í„°ì—ì„œ ìë™ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¼ì´ë“œ & íŒ¨ë”© íš¨ê³¼: ì¶œë ¥ í¬ê¸° ë³€í™”\n",
    "x = torch.randn(1, 3, 32, 32)  # (Batch, Channel, H, W)\n",
    "\n",
    "configs = [\n",
    "    ('K=3, S=1, P=0', dict(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=0)),\n",
    "    ('K=3, S=1, P=1', dict(in_channels=3, out_channels=1, kernel_size=3, stride=1, padding=1)),\n",
    "    ('K=3, S=2, P=0', dict(in_channels=3, out_channels=1, kernel_size=3, stride=2, padding=0)),\n",
    "    ('K=3, S=2, P=1', dict(in_channels=3, out_channels=1, kernel_size=3, stride=2, padding=1)),\n",
    "    ('K=5, S=1, P=0', dict(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=0)),\n",
    "    ('K=5, S=1, P=2', dict(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=2)),\n",
    "]\n",
    "\n",
    "print(f'ì…ë ¥ í¬ê¸°: {x.shape}  (B=1, C=3, H=32, W=32)\\n')\n",
    "print(f'{\"ì„¤ì •\":<18} {\"ì¶œë ¥ í¬ê¸°\":<12} {\"ê³µì‹ ê³„ì‚°\":>20}')\n",
    "print('-' * 56)\n",
    "\n",
    "for name, cfg in configs:\n",
    "    conv = nn.Conv2d(**cfg)\n",
    "    with torch.no_grad():\n",
    "        out = conv(x)\n",
    "    K = cfg['kernel_size']; S = cfg['stride']; P = cfg['padding']\n",
    "    H_formula = (32 - K + 2*P) // S + 1\n",
    "    print(f'{name:<18} {str(tuple(out.shape)):<12} {f\"({32}-{K}+2Ã—{P})/{S}+1 = {H_formula}\":>20}')\n",
    "\n",
    "print()\n",
    "print('ğŸ“Œ í•µì‹¬ ê·œì¹™:')\n",
    "print('  - P=K//2, S=1 â†’ ì¶œë ¥ í¬ê¸° = ì…ë ¥ í¬ê¸°  (\"same\" padding)')\n",
    "print('  - S=2          â†’ ì¶œë ¥ í¬ê¸° â‰ˆ ì…ë ¥ í¬ê¸° / 2  (ê³µê°„ ë‹¤ìš´ìƒ˜í”Œë§)')\n",
    "\n",
    "# ìŠ¤íŠ¸ë¼ì´ë“œë³„ íŠ¹ì„±ë§µ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3.5))\n",
    "\n",
    "img_t = denorm(img_tensor).unsqueeze(0)  # (1,3,32,32)\n",
    "stride_configs = [\n",
    "    ('ì›ë³¸ 32Ã—32',          img_t[0].mean(0).numpy()),\n",
    "    ('S=1, P=0 â†’ 30Ã—30',   nn.Conv2d(3,1,3,stride=1,padding=0)(img_t)[0,0].detach().numpy()),\n",
    "    ('S=1, P=1 â†’ 32Ã—32',   nn.Conv2d(3,1,3,stride=1,padding=1)(img_t)[0,0].detach().numpy()),\n",
    "    ('S=2, P=1 â†’ 16Ã—16',   nn.Conv2d(3,1,3,stride=2,padding=1)(img_t)[0,0].detach().numpy()),\n",
    "]\n",
    "\n",
    "for ax, (title, fmap) in zip(axes, stride_configs):\n",
    "    ax.imshow(fmap, cmap='viridis')\n",
    "    ax.set_title(title, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('ìŠ¤íŠ¸ë¼ì´ë“œ & íŒ¨ë”©ì— ë”°ë¥¸ ì¶œë ¥ í¬ê¸° ë³€í™”', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆ˜ìš© ì˜ì—­ (Receptive Field) ê°œë… ì‹œê°í™”\n",
    "# ë ˆì´ì–´ë¥¼ ìŒ“ì„ìˆ˜ë¡ ê° ì¶œë ¥ ë‰´ëŸ°ì´ 'ë³´ëŠ”' ì…ë ¥ ì˜ì—­ì´ ë„“ì–´ì§‘ë‹ˆë‹¤\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 4))\n",
    "\n",
    "def draw_receptive(ax, grid_size, rf_size, title, detail=''):\n",
    "    \"\"\"ê²©ìì—ì„œ ìˆ˜ìš© ì˜ì—­ì„ ì‹œê°í™”\"\"\"\n",
    "    ax.set_xlim(-0.5, grid_size - 0.5)\n",
    "    ax.set_ylim(-0.5, grid_size - 0.5)\n",
    "    ax.set_aspect('equal')\n",
    "    # ê²©ì\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            color = '#e8f4f8'\n",
    "            rect = plt.Rectangle((j-0.5, i-0.5), 1, 1, fill=True, facecolor=color, edgecolor='gray', lw=0.5)\n",
    "            ax.add_patch(rect)\n",
    "    # ìˆ˜ìš© ì˜ì—­ ê°•ì¡°\n",
    "    offset = (grid_size - rf_size) // 2\n",
    "    for i in range(rf_size):\n",
    "        for j in range(rf_size):\n",
    "            ri, rj = offset + i, offset + j\n",
    "            rect = plt.Rectangle((rj-0.5, ri-0.5), 1, 1, fill=True, facecolor='#ff7f7f', edgecolor='darkred', lw=1.5)\n",
    "            ax.add_patch(rect)\n",
    "    # ì¤‘ì‹¬ ë‰´ëŸ° í‘œì‹œ\n",
    "    cx = cy = grid_size // 2\n",
    "    ax.plot(cx, cy, 'b*', ms=12, zorder=5)\n",
    "    ax.set_title(f'{title}\\nRF = {rf_size}Ã—{rf_size}', fontsize=9)\n",
    "    ax.set_xlabel(detail, fontsize=8)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "draw_receptive(axes[0], 9, 1, 'ì…ë ¥ì¸µ', 'ê° ë‰´ëŸ° â†’ 1Ã—1 í”½ì…€')\n",
    "draw_receptive(axes[1], 9, 3, 'Conv(3Ã—3) Ã— 1', '1ê°œ conv â†’ RF=3Ã—3')\n",
    "draw_receptive(axes[2], 9, 5, 'Conv(3Ã—3) Ã— 2', '2ê°œ conv â†’ RF=5Ã—5')\n",
    "draw_receptive(axes[3], 9, 9, 'Conv(3Ã—3) Ã— 4', '4ê°œ conv â†’ RF=9Ã—9')\n",
    "\n",
    "plt.suptitle('ìˆ˜ìš© ì˜ì—­(Receptive Field): 3Ã—3 í•©ì„±ê³±ì„ ìŒ“ì„ìˆ˜ë¡ í™•ëŒ€', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('=== ìˆ˜ìš© ì˜ì—­ í¬ê¸° (3Ã—3 conv ë°˜ë³µ) ===')\n",
    "rf = 1\n",
    "for k in range(1, 6):\n",
    "    rf = rf + 2  # ê° 3Ã—3 convë§ˆë‹¤ +2\n",
    "    print(f'  {k}ê°œ conv(3Ã—3) í›„: RF = {rf}Ã—{rf}')\n",
    "\n",
    "print()\n",
    "print('ğŸ“Œ í•µì‹¬: 3Ã—3 í•„í„°ë¥¼ ìŒ“ëŠ” ê²ƒì´ í° í•„í„° í•˜ë‚˜ë³´ë‹¤ íš¨ìœ¨ì !')\n",
    "print('   - 3Ã—3 Ã— 2 = íŒŒë¼ë¯¸í„° 2Ã—(3Ã—3)=18ê°œ,  RF=5Ã—5')\n",
    "print('   - 5Ã—5 Ã— 1 = íŒŒë¼ë¯¸í„° 1Ã—(5Ã—5)=25ê°œ,  RF=5Ã—5')\n",
    "print('   â†’ ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ê°™ì€ ìˆ˜ìš© ì˜ì—­ ë‹¬ì„± (VGG í•µì‹¬ ì•„ì´ë””ì–´)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2. CNN êµ¬í˜„ â€” LeNet\n",
    "\n",
    "### 2-1. MLP vs CNN ë¹„êµ\n",
    "\n",
    "| | MLP (Flatten) | CNN (LeNet) |\n",
    "|---|---|---|\n",
    "| **ì…ë ¥ ì²˜ë¦¬** | ëª¨ë“  í”½ì…€ì„ 1Dë¡œ í¼ì¹¨ | 2D ê³µê°„ êµ¬ì¡° ìœ ì§€ |\n",
    "| **ê³µê°„ ê´€ê³„** | ë¬´ì‹œ | ìœ„ì¹˜ ë¶ˆë³€ì„±(translation invariance) í•™ìŠµ |\n",
    "| **íŒŒë¼ë¯¸í„°** | ë§¤ìš° ë§ìŒ (3Ã—32Ã—32=3072 â†’ ...) | ì ìŒ (ê°€ì¤‘ì¹˜ ê³µìœ ) |\n",
    "| **ì„±ëŠ¥** | ë‚®ìŒ | ë†’ìŒ |\n",
    "\n",
    "### 2-2. LeNet-5 êµ¬ì¡° (CIFAR-10 ìˆ˜ì • ë²„ì „)\n",
    "\n",
    "```\n",
    "ì…ë ¥ (3Ã—32Ã—32)\n",
    "  â”‚\n",
    "Conv(3â†’6, k=5) â†’ ReLU â†’ MaxPool(2)   : (6Ã—14Ã—14)\n",
    "  â”‚\n",
    "Conv(6â†’16, k=5) â†’ ReLU â†’ MaxPool(2)  : (16Ã—5Ã—5)\n",
    "  â”‚\n",
    "Flatten â†’ Linear(400â†’120) â†’ ReLU\n",
    "  â”‚\n",
    "Linear(120â†’84) â†’ ReLU\n",
    "  â”‚\n",
    "Linear(84â†’10)  â†’ ì¶œë ¥ (10 í´ë˜ìŠ¤)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Baseline & LeNet í´ë˜ìŠ¤ ì •ì˜\n",
    "\n",
    "class MLP_CIFAR(nn.Module):\n",
    "    \"\"\"CIFAR-10 MLP baseline: ì´ë¯¸ì§€ë¥¼ 1Dë¡œ í¼ì³ì„œ ë¶„ë¥˜\"\"\"\n",
    "    def __init__(self, hidden_dims=(512, 256), dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = [nn.Flatten()]\n",
    "        in_dim = 3 * 32 * 32\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, 10))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    \"\"\"LeNet-5 (CIFAR-10 ìˆ˜ì • ë²„ì „): 3Ã—32Ã—32 ì…ë ¥\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),    # (3,32,32) â†’ (6,28,28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # (6,28,28) â†’ (6,14,14)\n",
    "            nn.Conv2d(6, 16, kernel_size=5),   # (6,14,14) â†’ (16,10,10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                # (16,10,10) â†’ (16,5,5)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "# êµ¬ì¡° í™•ì¸\n",
    "mlp   = MLP_CIFAR()\n",
    "lenet = LeNet()\n",
    "\n",
    "print('=== MLP_CIFAR êµ¬ì¡° ===')\n",
    "print(mlp)\n",
    "print(f'\\nì´ íŒŒë¼ë¯¸í„°: {count_params(mlp):,}')\n",
    "\n",
    "print('\\n=== LeNet êµ¬ì¡° ===')\n",
    "print(lenet)\n",
    "print(f'\\nì´ íŒŒë¼ë¯¸í„°: {count_params(lenet):,}')\n",
    "\n",
    "# ìˆœì „íŒŒ í¬ê¸° í™•ì¸\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, 32, 32)\n",
    "    print(f'\\nì…ë ¥:        {dummy.shape}')\n",
    "    print(f'conv1 ì¶œë ¥:  {lenet.features[:2](dummy).shape}')\n",
    "    print(f'pool1 ì¶œë ¥:  {lenet.features[:3](dummy).shape}')\n",
    "    print(f'conv2 ì¶œë ¥:  {lenet.features[:5](dummy).shape}')\n",
    "    print(f'pool2 ì¶œë ¥:  {lenet.features(dummy).shape}')\n",
    "    print(f'ìµœì¢… ì¶œë ¥:   {lenet(dummy).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³µìœ  í•™ìŠµ í•¨ìˆ˜\n",
    "\n",
    "def train_cnn(model, train_loader, test_loader,\n",
    "              n_epochs=15, lr=0.001, verbose=True):\n",
    "    \"\"\"CNN/MLP í•™ìŠµ í•¨ìˆ˜ (ë””ë°”ì´ìŠ¤ ìë™ ì²˜ë¦¬)\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # --- í•™ìŠµ ---\n",
    "        model.train()\n",
    "        ep_loss, correct, total = 0., 0, 0\n",
    "        for X, y in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ep_loss  += loss.item() * len(X)\n",
    "            correct  += (logits.argmax(1) == y).sum().item()\n",
    "            total    += len(y)\n",
    "\n",
    "        train_losses.append(ep_loss / total)\n",
    "        train_accs.append(correct / total)\n",
    "\n",
    "        # --- ê²€ì¦ ---\n",
    "        model.eval()\n",
    "        v_loss, v_correct, v_total = 0., 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                logits = model(X)\n",
    "                v_loss   += criterion(logits, y).item() * len(X)\n",
    "                v_correct += (logits.argmax(1) == y).sum().item()\n",
    "                v_total   += len(y)\n",
    "\n",
    "        val_losses.append(v_loss / v_total)\n",
    "        val_accs.append(v_correct / v_total)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Epoch {epoch+1:2d}/{n_epochs} | '\n",
    "                  f'Train {train_losses[-1]:.4f}/{train_accs[-1]:.4f} | '\n",
    "                  f'Val {val_losses[-1]:.4f}/{val_accs[-1]:.4f}')\n",
    "\n",
    "    model.cpu()\n",
    "    return train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "\n",
    "print('train_cnn() í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!')\n",
    "print(f'í•™ìŠµ ë””ë°”ì´ìŠ¤: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP vs LeNet í•™ìŠµ ë° ë¹„êµ (n_epochs=15)\n",
    "print('=== MLP_CIFAR í•™ìŠµ ===')\n",
    "torch.manual_seed(42)\n",
    "model_mlp = MLP_CIFAR()\n",
    "mlp_tl, mlp_vl, mlp_ta, mlp_va = train_cnn(model_mlp, train_loader, test_loader, n_epochs=15)\n",
    "\n",
    "print('\\n=== LeNet í•™ìŠµ ===')\n",
    "torch.manual_seed(42)\n",
    "model_lenet = LeNet()\n",
    "ln_tl, ln_vl, ln_ta, ln_va = train_cnn(model_lenet, train_loader, test_loader, n_epochs=15)\n",
    "\n",
    "# ë¹„êµ ì‹œê°í™”\n",
    "ep = range(1, 16)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "for (name, vl, va, color) in [\n",
    "    (f'MLP  (params={count_params(model_mlp):,})',   mlp_vl, mlp_va, 'steelblue'),\n",
    "    (f'LeNet(params={count_params(model_lenet):,})', ln_vl,  ln_va,  'tomato'),\n",
    "]:\n",
    "    axes[0].plot(ep, vl, color=color, lw=2, label=name)\n",
    "    axes[1].plot(ep, va, color=color, lw=2, label=f'{name} ({va[-1]:.4f})')\n",
    "\n",
    "for ax, title, ylabel in [\n",
    "    (axes[0], 'MLP vs LeNet: Val Loss',     'CrossEntropy Loss'),\n",
    "    (axes[1], 'MLP vs LeNet: Val Accuracy', 'Accuracy'),\n",
    "]:\n",
    "    ax.set_title(title); ax.set_xlabel('ì—í¬í¬')\n",
    "    ax.set_ylabel(ylabel); ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('MLP vs LeNet â€” CIFAR-10 ë¶„ë¥˜ (10,000 í•™ìŠµ ìƒ˜í”Œ, 15 ì—í¬í¬)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nìµœì¢… Val Accuracy')\n",
    "print(f'  MLP  : {mlp_va[-1]:.4f}  ({count_params(model_mlp):,} params)')\n",
    "print(f'  LeNet: {ln_va[-1]:.4f}  ({count_params(model_lenet):,} params)')\n",
    "print(f'  â†’ LeNetì´ {count_params(model_mlp)//count_params(model_lenet)}ë°° ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ë” ë†’ì€ ì„±ëŠ¥!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ í•„í„° & Feature Map ì‹œê°í™”\n",
    "\n",
    "# --- Conv1 í•„í„° ì‹œê°í™” (í•™ìŠµëœ 6ê°œ í•„í„°) ---\n",
    "conv1_weights = model_lenet.features[0].weight.data  # (6, 3, 5, 5)\n",
    "fig, axes = plt.subplots(1, 6, figsize=(12, 2.5))\n",
    "for i in range(6):\n",
    "    # 3ì±„ë„ í•„í„°ë¥¼ RGBë¡œ ì‹œê°í™”\n",
    "    filt = conv1_weights[i].permute(1, 2, 0).numpy()  # (5,5,3)\n",
    "    filt = (filt - filt.min()) / (filt.max() - filt.min() + 1e-8)\n",
    "    axes[i].imshow(filt)\n",
    "    axes[i].set_title(f'í•„í„° {i+1}', fontsize=9)\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle('LeNet Conv1 í•™ìŠµëœ í•„í„° (6ê°œ, 5Ã—5Ã—3)', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Feature Map ì‹œê°í™” (íŠ¹ì • ì´ë¯¸ì§€) ---\n",
    "activations = {}\n",
    "\n",
    "def make_hook(name):\n",
    "    def hook(module, inp, out):\n",
    "        activations[name] = out.detach()\n",
    "    return hook\n",
    "\n",
    "h1 = model_lenet.features[0].register_forward_hook(make_hook('conv1'))  # Conv2d\n",
    "h2 = model_lenet.features[3].register_forward_hook(make_hook('conv2'))  # Conv2d\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í•œ ì¥ forward\n",
    "sample_img, sample_lbl = testset_full[7]\n",
    "with torch.no_grad():\n",
    "    _ = model_lenet(sample_img.unsqueeze(0))\n",
    "\n",
    "h1.remove(); h2.remove()\n",
    "\n",
    "fig, axes = plt.subplots(3, 8, figsize=(15, 6))\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€\n",
    "orig = denorm(sample_img).permute(1, 2, 0).numpy()\n",
    "axes[0, 0].imshow(orig)\n",
    "axes[0, 0].set_title(f'ì›ë³¸\\n({classes[sample_lbl]})', fontsize=8)\n",
    "for j in range(1, 8): axes[0, j].axis('off')\n",
    "\n",
    "# Conv1 feature maps (6ê°œ)\n",
    "fmaps1 = activations['conv1'][0]  # (6, 28, 28)\n",
    "for i in range(6):\n",
    "    axes[1, i].imshow(fmaps1[i].numpy(), cmap='viridis')\n",
    "    axes[1, i].set_title(f'Conv1[{i+1}]\\n28Ã—28', fontsize=8)\n",
    "    axes[1, i].axis('off')\n",
    "for j in range(6, 8): axes[1, j].axis('off')\n",
    "\n",
    "# Conv2 feature maps (8ê°œ ì¤‘ ì²˜ìŒ 8ê°œ)\n",
    "fmaps2 = activations['conv2'][0]  # (16, 10, 10)\n",
    "for i in range(8):\n",
    "    axes[2, i].imshow(fmaps2[i].numpy(), cmap='viridis')\n",
    "    axes[2, i].set_title(f'Conv2[{i+1}]\\n10Ã—10', fontsize=8)\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "axes[0, 0].axis('on'); axes[0, 0].set_xticks([]); axes[0, 0].set_yticks([])\n",
    "axes[0, 0].set_ylabel('ì…ë ¥', fontsize=9)\n",
    "axes[1, 0].set_ylabel('Conv1\\n(6ch)', fontsize=9)\n",
    "axes[2, 0].set_ylabel('Conv2\\n(16ch)', fontsize=9)\n",
    "\n",
    "plt.suptitle(f'LeNet Feature Maps â€” {classes[sample_lbl]}', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ğŸ“Œ ê´€ì°°: ì´ˆê¸° ë ˆì´ì–´ëŠ” edge/textureë¥¼, ê¹Šì€ ë ˆì´ì–´ëŠ” ê³ ìˆ˜ì¤€ íŒ¨í„´ì„ ê°ì§€í•©ë‹ˆë‹¤.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3. ë” ê¹Šì€ CNN â€” VGG-style\n",
    "\n",
    "### 3-1. VGGNet í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "2014ë…„ Oxford VGGíŒ€ì´ ì œì•ˆí•œ VGGNetì˜ í•µì‹¬ì€ **3Ã—3 í•©ì„±ê³±ë§Œ ë°˜ë³µ ì‚¬ìš©**ì…ë‹ˆë‹¤.\n",
    "\n",
    "| íŠ¹ì§• | ë‚´ìš© |\n",
    "|---|---|\n",
    "| ëª¨ë“  conv | 3Ã—3, padding=1 (same) |\n",
    "| ë‹¤ìš´ìƒ˜í”Œë§ | MaxPool(2Ã—2)ë§Œ ì‚¬ìš© |\n",
    "| ì±„ë„ ìˆ˜ | ë¸”ë¡ë§ˆë‹¤ 2ë°° (32â†’64â†’128) |\n",
    "| ì •ê·œí™” | BatchNorm + Dropout |\n",
    "\n",
    "### 3-2. VGG-style ë¸”ë¡ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "Block 1: Conv(3â†’32)â†’BNâ†’ReLU â†’ Conv(32â†’32)â†’BNâ†’ReLU â†’ MaxPool â†’ Dropout2d(0.1)\n",
    "         ì…ë ¥ 32Ã—32 â†’ ì¶œë ¥ 16Ã—16\n",
    "\n",
    "Block 2: Conv(32â†’64)â†’BNâ†’ReLU â†’ Conv(64â†’64)â†’BNâ†’ReLU â†’ MaxPool â†’ Dropout2d(0.2)\n",
    "         ì…ë ¥ 16Ã—16 â†’ ì¶œë ¥ 8Ã—8\n",
    "\n",
    "Block 3: Conv(64â†’128)â†’BNâ†’ReLU â†’ Conv(128â†’128)â†’BNâ†’ReLU â†’ MaxPool\n",
    "         ì…ë ¥ 8Ã—8 â†’ ì¶œë ¥ 4Ã—4\n",
    "\n",
    "Classifier: Flatten(128Ã—4Ã—4=2048) â†’ Linear(256) â†’ ReLU â†’ Dropout â†’ Linear(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-style CNN í´ë˜ìŠ¤\n",
    "\n",
    "def vgg_block(in_ch, out_ch, dropout2d=0.0):\n",
    "    \"\"\"VGG-style ë¸”ë¡: ConvÃ—2 + BN + ReLU + MaxPool (+ ì„ íƒì  Dropout2d)\"\"\"\n",
    "    layers = [\n",
    "        nn.Conv2d(in_ch,  out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(),\n",
    "        nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(),\n",
    "        nn.MaxPool2d(2, 2),\n",
    "    ]\n",
    "    if dropout2d > 0:\n",
    "        layers.append(nn.Dropout2d(dropout2d))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class VGGNet(nn.Module):\n",
    "    \"\"\"ì†Œí˜• VGG-style CNN for CIFAR-10\"\"\"\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            vgg_block(3,   32,  dropout2d=0.1),   # 32Ã—32 â†’ 16Ã—16\n",
    "            vgg_block(32,  64,  dropout2d=0.2),   # 16Ã—16 â†’  8Ã—8\n",
    "            vgg_block(64,  128, dropout2d=0.0),   #  8Ã—8  â†’  4Ã—4\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "\n",
    "# êµ¬ì¡° í™•ì¸\n",
    "vgg = VGGNet()\n",
    "print('=== VGGNet êµ¬ì¡° ===')\n",
    "print(vgg)\n",
    "print(f'\\nì´ íŒŒë¼ë¯¸í„°: {count_params(vgg):,}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, 32, 32)\n",
    "    for i, block in enumerate(vgg.features):\n",
    "        dummy = block(dummy)\n",
    "        print(f'Block {i+1} ì¶œë ¥: {dummy.shape}')\n",
    "    print(f'Flatten: {dummy.view(1,-1).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet vs VGGNet ë¹„êµ í•™ìŠµ\n",
    "print('=== VGGNet í•™ìŠµ ===')\n",
    "torch.manual_seed(42)\n",
    "model_vgg = VGGNet()\n",
    "vgg_tl, vgg_vl, vgg_ta, vgg_va = train_cnn(model_vgg, train_loader, test_loader, n_epochs=15)\n",
    "\n",
    "# 3ê°œ ëª¨ë¸ ë¹„êµ ì‹œê°í™”\n",
    "ep = range(1, 16)\n",
    "results = [\n",
    "    ('MLP',    mlp_va,  mlp_vl,  'steelblue', count_params(model_mlp)),\n",
    "    ('LeNet',  ln_va,   ln_vl,   'tomato',    count_params(model_lenet)),\n",
    "    ('VGGNet', vgg_va,  vgg_vl,  'seagreen',  count_params(model_vgg)),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "for name, va, vl, color, _ in results:\n",
    "    axes[0].plot(ep, vl, color=color, lw=2, label=name)\n",
    "    axes[1].plot(ep, va, color=color, lw=2, label=f'{name} ({va[-1]:.4f})')\n",
    "\n",
    "for ax, title, ylabel in [\n",
    "    (axes[0], 'Val Loss ë¹„êµ',     'Loss'),\n",
    "    (axes[1], 'Val Accuracy ë¹„êµ', 'Accuracy'),\n",
    "]:\n",
    "    ax.set_title(title); ax.set_xlabel('ì—í¬í¬')\n",
    "    ax.set_ylabel(ylabel); ax.legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('MLP vs LeNet vs VGGNet â€” CIFAR-10 (15 ì—í¬í¬)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì„±ëŠ¥ í‘œ\n",
    "print(f'\\n{\"ëª¨ë¸\":<10} {\"Val Acc\":>10} {\"íŒŒë¼ë¯¸í„°\":>12}')\n",
    "print('-' * 36)\n",
    "for name, va, _, _, n_p in results:\n",
    "    mark = ' â˜…' if va[-1] == max(r[1][-1] for r in results) else ''\n",
    "    print(f'{name:<10} {va[-1]:>10.4f} {n_p:>12,}{mark}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise\n",
    "\n",
    "### Exercise 1. LeNet_wide â€” ì±„ë„ ìˆ˜ í™•ì¥ ì‹¤í—˜\n",
    "\n",
    "ê¸°ì¤€ LeNetì˜ í•„í„° ì±„ë„ ìˆ˜ë¥¼ **2ë°°**ë¡œ ëŠ˜ë¦° `LeNet_wide`ë¥¼ êµ¬í˜„í•˜ê³  ë¹„êµí•˜ì„¸ìš”.\n",
    "\n",
    "| ë ˆì´ì–´ | LeNet (ê¸°ì¤€) | LeNet_wide |\n",
    "|---|---|---|\n",
    "| Conv1 | 3 â†’ 6 | 3 â†’ 12 |\n",
    "| Conv2 | 6 â†’ 16 | 12 â†’ 32 |\n",
    "| FC1 | 400 â†’ 120 | **32Ã—5Ã—5** â†’ 240 |\n",
    "| FC2 | 120 â†’ 84 | 240 â†’ 168 |\n",
    "| FC3 | 84 â†’ 10 | 168 â†’ 10 |\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "1. `LeNet_wide` í´ë˜ìŠ¤ êµ¬í˜„ (LeNetê³¼ ë™ì¼í•œ êµ¬ì¡°, ì±„ë„ ìˆ˜ë§Œ 2ë°°)\n",
    "2. ë™ì¼ ì¡°ê±´ìœ¼ë¡œ í•™ìŠµ (n_epochs=15, Adam, lr=0.001)\n",
    "3. Val Accuracy ê³¡ì„  ë¹„êµ + íŒŒë¼ë¯¸í„° ìˆ˜ ë° ìµœì¢… Val Acc ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: LeNet_wide êµ¬í˜„\n",
    "\n",
    "class LeNet_wide(nn.Module):\n",
    "    \"\"\"LeNet ì±„ë„ ìˆ˜ 2ë°° í™•ì¥ ë²„ì „\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your code here: features ì •ì˜\n",
    "        #   Conv(3â†’12, k=5) â†’ ReLU â†’ MaxPool(2)\n",
    "        #   Conv(12â†’32, k=5) â†’ ReLU â†’ MaxPool(2)\n",
    "        self.features = None\n",
    "\n",
    "        # Your code here: classifier ì •ì˜\n",
    "        #   Flatten â†’ Linear(32*5*5, 240) â†’ ReLU\n",
    "        #   Linear(240, 168) â†’ ReLU\n",
    "        #   Linear(168, 10)\n",
    "        self.classifier = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "\n",
    "# Your code here: LeNet_wide í•™ìŠµ (n_epochs=15, lr=0.001)\n",
    "torch.manual_seed(42)\n",
    "model_lenet_wide = LeNet_wide()\n",
    "\n",
    "# lw_tl, lw_vl, lw_ta, lw_va = train_cnn(model_lenet_wide, train_loader, test_loader, n_epochs=15)\n",
    "\n",
    "# Your code here: LeNet vs LeNet_wide Val Accuracy ê³¡ì„  ë¹„êµ\n",
    "\n",
    "# Your code here: íŒŒë¼ë¯¸í„° ìˆ˜ ë° ìµœì¢… Val Acc ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md2",
   "metadata": {},
   "source": [
    "### Exercise 2. Feature Map ì‹œê°í™”\n",
    "\n",
    "í•™ìŠµëœ **VGGNet**ì˜ ê° Block ì¶œë ¥ feature mapì„ ì¶”ì¶œí•˜ê³  ì‹œê°í™”í•˜ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "1. `register_forward_hook`ì„ ì‚¬ìš©í•´ Block 1, 2, 3 ì¶œë ¥ ì €ì¥\n",
    "2. í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ì´ë¯¸ì§€ 1ì¥ ì„ íƒ (ì„ì˜ ì„ íƒ ê°€ëŠ¥)\n",
    "3. ê° ë¸”ë¡ì˜ feature mapì„ ì±„ë„ ìµœëŒ€ 8ê°œ ì‹œê°í™” (ì´ 3í–‰Ã—8ì—´)\n",
    "4. ë¸”ë¡ì´ ê¹Šì–´ì§ˆìˆ˜ë¡ feature map í¬ê¸°ì™€ ë‚´ìš©ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ê´€ì°°\n",
    "\n",
    "**íŒíŠ¸:**\n",
    "```python\n",
    "handle = model.features[0].register_forward_hook(make_hook('block1'))\n",
    "# ... forward pass ...\n",
    "handle.remove()  # hook í•´ì œ!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: VGGNet Feature Map ì‹œê°í™”\n",
    "\n",
    "# Your code here: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ íƒ\n",
    "# sample_img, sample_lbl = testset_full[?]\n",
    "\n",
    "# Your code here: Block 1, 2, 3ì— hook ë“±ë¡\n",
    "# h1 = model_vgg.features[0].register_forward_hook(...)\n",
    "# h2 = ...\n",
    "# h3 = ...\n",
    "\n",
    "# Your code here: forward pass ì‹¤í–‰\n",
    "# model_vgg.eval()\n",
    "# with torch.no_grad():\n",
    "#     _ = model_vgg(sample_img.unsqueeze(0))\n",
    "\n",
    "# Your code here: hook í•´ì œ\n",
    "\n",
    "# Your code here: 3í–‰Ã—8ì—´ feature map ì‹œê°í™”\n",
    "# - í–‰: Block 1 / Block 2 / Block 3\n",
    "# - ì—´: ì±„ë„ 0~7 (ìµœëŒ€ 8ê°œ)\n",
    "# - ê° subplotì— í¬ê¸° ì •ë³´ í‘œì‹œ (ì˜ˆ: '16Ã—16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md3",
   "metadata": {},
   "source": [
    "### Exercise 3. (ë„ì „) Global Average Pooling (GAP)\n",
    "\n",
    "VGGNetì˜ ëŒ€í˜• FC ë¶„ë¥˜ê¸° ëŒ€ì‹  **Global Average Pooling**ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ í¬ê²Œ ì¤„ì´ì„¸ìš”.\n",
    "\n",
    "**GAP ì‘ë™ ë°©ì‹:**\n",
    "```\n",
    "ì¼ë°˜ Flatten:  (B, 128, 4, 4) â†’ (B, 2048)  â†’ Linear(2048â†’256) â†’ ...\n",
    "GAP:           (B, 128, 4, 4) â†’ GAP â†’ (B, 128) â†’ Linear(128â†’10)  # FC 1ê°œë§Œ!\n",
    "```\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "1. `GAP_CNN` í´ë˜ìŠ¤ êµ¬í˜„ (`nn.AdaptiveAvgPool2d(1)` ì‚¬ìš©)\n",
    "   - `features`ëŠ” VGGNetê³¼ ë™ì¼\n",
    "   - `classifier`ëŠ” GAP â†’ Flatten â†’ Linear(128, 10) ë§Œ\n",
    "2. ë™ì¼ ì¡°ê±´ìœ¼ë¡œ í•™ìŠµ (n_epochs=15)\n",
    "3. VGGNet vs GAP_CNN: íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ ë° Val Accuracy ë¹„êµ\n",
    "\n",
    "**íŒíŠ¸:**\n",
    "```python\n",
    "self.gap = nn.AdaptiveAvgPool2d(1)  # (B,C,H,W) â†’ (B,C,1,1)\n",
    "# forwardì—ì„œ: x = self.gap(x).squeeze(-1).squeeze(-1)  â†’ (B,C)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Global Average Pooling CNN\n",
    "\n",
    "class GAP_CNN(nn.Module):\n",
    "    \"\"\"Global Average Poolingì„ ì‚¬ìš©í•˜ëŠ” CNN\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your code here: features (VGGNetê³¼ ë™ì¼í•œ 3ê°œ ë¸”ë¡)\n",
    "        self.features = None\n",
    "\n",
    "        # Your code here: GAP layer (AdaptiveAvgPool2d(1))\n",
    "        self.gap = None\n",
    "\n",
    "        # Your code here: classifier (Linear(128, 10)ë§Œ)\n",
    "        self.classifier = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here:\n",
    "        # 1. features í†µê³¼\n",
    "        # 2. GAP ì ìš©\n",
    "        # 3. squeeze\n",
    "        # 4. classifier ì ìš©\n",
    "        pass\n",
    "\n",
    "\n",
    "# Your code here: GAP_CNN í•™ìŠµ (n_epochs=15)\n",
    "torch.manual_seed(42)\n",
    "model_gap = GAP_CNN()\n",
    "\n",
    "# gap_tl, gap_vl, gap_ta, gap_va = train_cnn(model_gap, train_loader, test_loader, n_epochs=15)\n",
    "\n",
    "# Your code here: VGGNet vs GAP_CNN\n",
    "# - íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ\n",
    "# - Val Accuracy ê³¡ì„  ë¹„êµ\n",
    "# - ê²°ê³¼ í•´ì„: ì ì€ íŒŒë¼ë¯¸í„°ë¡œ ë¹„ìŠ·í•œ ì„±ëŠ¥ì´ ë‚˜ì˜¤ëŠ”ê°€?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| ê°œë… | í•µì‹¬ ë‚´ìš© |\n",
    "|---|---|\n",
    "| **í•©ì„±ê³± ì—°ì‚°** | í•„í„°ê°€ ì´ë¯¸ì§€ ìœ„ë¥¼ ìŠ¬ë¼ì´ë”©í•˜ë©° ë‚´ì  ê³„ì‚° |\n",
    "| **íŠ¹ì„±ë§µ** | ê° í•„í„°ë§ˆë‹¤ í•˜ë‚˜ì”© ìƒì„±ë˜ëŠ” ì¶œë ¥ |\n",
    "| **ìˆ˜ìš© ì˜ì—­** | ê° ì¶œë ¥ ë‰´ëŸ°ì´ ì°¸ì¡°í•˜ëŠ” ì…ë ¥ ì˜ì—­; ë ˆì´ì–´ ì¦ê°€ ì‹œ í™•ì¥ |\n",
    "| **ìŠ¤íŠ¸ë¼ì´ë“œ** | í•„í„° ì´ë™ ë³´í­; S=2ì´ë©´ ì¶œë ¥ í¬ê¸° Â½ |\n",
    "| **íŒ¨ë”©** | ê°€ì¥ìë¦¬ 0 ì¶”ê°€; same paddingìœ¼ë¡œ í¬ê¸° ìœ ì§€ |\n",
    "| **MaxPooling** | ì§€ì—­ ìµœëŒ“ê°’ ì¶”ì¶œ; ê³µê°„ ë‹¤ìš´ìƒ˜í”Œë§ + ìœ„ì¹˜ ë¶ˆë³€ì„± |\n",
    "| **LeNet** | ConvÃ—2 + MaxPoolÃ—2 + FCÃ—3; ì´ˆê¸° CNN ê¸°ì¤€ ëª¨ë¸ |\n",
    "| **VGGNet** | 3Ã—3 conv ë°˜ë³µ + MaxPool; 3Ã—3Ã—2 = 5Ã—5 ë™ì¼ RF, ì ì€ íŒŒë¼ë¯¸í„° |\n",
    "| **BatchNorm (CNN)** | BatchNorm2d; ì±„ë„ë³„ ì •ê·œí™”, í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ |\n",
    "| **ê°€ì¤‘ì¹˜ ê³µìœ ** | ê°™ì€ í•„í„°ë¥¼ ì´ë¯¸ì§€ ì „ì²´ì— ê³µìœ  â†’ íŒŒë¼ë¯¸í„° íš¨ìœ¨ |\n",
    "| **GAP** | FC ë¶„ë¥˜ê¸° ëŒ€ì‹  ì±„ë„ë³„ í‰ê·  â†’ íŒŒë¼ë¯¸í„° ëŒ€í­ ê°ì†Œ |\n",
    "\n",
    "---\n",
    "\n",
    "**ë‹¤ìŒ ê°•ì˜ (Week 13):** RNN â€” ìˆœí™˜ ì‹ ê²½ë§, LSTM, ì‹œê³„ì—´ ë°ì´í„°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
