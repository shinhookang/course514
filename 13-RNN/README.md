# Week 13 — Recurrent Neural Networks

## Contents
- Vanilla RNN and the vanishing gradient problem
- LSTM: cell state, forget/input/output gates
- GRU: simplified gating mechanism
- Sequence-to-sequence modeling

## Lab
**Time-series / text (PyTorch)** — Use an LSTM to predict a time-series or classify text sequences.

---
[← Back to Course](../README.md)
