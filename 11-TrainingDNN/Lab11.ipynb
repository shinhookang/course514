{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c-title",
   "metadata": {},
   "source": "# Lab 11 — Training Deep Networks\n\n> **강의 시간:** 약 2시간\n> **주제:** 딥 신경망 학습: 옵티마이저, 정규화, 배치 정규화, 학습률 스케줄링\n\n---\n\n## 학습 목표\n\n| # | 목표 | 예상 시간 |\n|---|---|---|\n| 1 | 옵티마이저 비교: SGD, Momentum, RMSProp, Adam | 30분 |\n| 2 | 정규화 기법: L1/L2, Dropout | 25분 |\n| 3 | 배치 정규화 & 레이어 정규화 | 25분 |\n| 4 | 학습률 스케줄링 | 15분 |\n| 5 | Exercise | 25분 |\n\n---\n\n**데이터셋:**\n- 시각화: 합성 2D 데이터 (최적화 궤적, 과적합 비교)\n- 분류: Digits (sklearn) — 64개 특성, 10개 클래스 (손글씨 숫자 0–9)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-setup",
   "metadata": {},
   "outputs": [],
   "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nimport seaborn as sns\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n_fp = '/System/Library/Fonts/AppleGothic.ttf'\nfm.fontManager.addfont(_fp)\nplt.rcParams['font.family'] = fm.FontProperties(fname=_fp).get_name()\nplt.rcParams['axes.unicode_minus'] = False\nsns.set_theme(style='whitegrid')\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nprint(f'PyTorch version: {torch.__version__}')\ndevice = torch.device('cpu')\nprint(f'Using device   : {device}')"
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md",
   "metadata": {},
   "source": "---\n## Part 1. 옵티마이저 (Optimizers)\n\n### 1-1. 왜 다양한 옵티마이저가 필요한가?\n\n기본 경사 하강법(SGD)은 단순하지만, 실제 손실 지형(loss landscape)에서는 비효율적입니다.\n\n| 옵티마이저 | 업데이트 규칙 | 특징 |\n|---|---|---|\n| **SGD** | $w \\leftarrow w - \\eta \\nabla L$ | 단순, 느림, 하이퍼파라미터 민감 |\n| **Momentum** | $v \\leftarrow \\beta v + \\nabla L$; $w \\leftarrow w - \\eta v$ | 관성으로 지그재그 감소 |\n| **RMSProp** | $s \\leftarrow \\beta s + (1-\\beta)g^2$; $w \\leftarrow w - \\frac{\\eta}{\\sqrt{s+\\varepsilon}}g$ | 적응형 lr, 온라인 학습에 강함 |\n| **Adam** | Momentum + RMSProp 결합, 편향 보정 포함 | 대부분 상황에서 잘 작동 |\n\n### 1-2. 손실 지형 시각화\n\n$f(x, y) = x^2 + 10y^2$ (길쭉한 이차 함수)에서 각 옵티마이저의 최솟값 탐색 경로를 비교합니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code1",
   "metadata": {},
   "outputs": [],
   "source": "# 최적화 궤적 시각화: f(x, y) = x² + 10y²\ndef f(x, y):     return x**2 + 10*y**2\ndef grad_f(x, y): return 2*x, 20*y\n\ndef run_sgd(x0, y0, lr, n):\n    x, y = x0, y0; path = [(x, y)]\n    for _ in range(n):\n        gx, gy = grad_f(x, y); x -= lr*gx; y -= lr*gy; path.append((x, y))\n    return path\n\ndef run_momentum(x0, y0, lr, beta, n):\n    x, y, vx, vy = x0, y0, 0., 0.; path = [(x, y)]\n    for _ in range(n):\n        gx, gy = grad_f(x, y)\n        vx = beta*vx + gx; vy = beta*vy + gy\n        x -= lr*vx; y -= lr*vy; path.append((x, y))\n    return path\n\ndef run_rmsprop(x0, y0, lr, beta, eps, n):\n    x, y, sx, sy = x0, y0, 0., 0.; path = [(x, y)]\n    for _ in range(n):\n        gx, gy = grad_f(x, y)\n        sx = beta*sx + (1-beta)*gx**2; sy = beta*sy + (1-beta)*gy**2\n        x -= lr*gx/(np.sqrt(sx)+eps); y -= lr*gy/(np.sqrt(sy)+eps)\n        path.append((x, y))\n    return path\n\ndef run_adam(x0, y0, lr, b1, b2, eps, n):\n    x, y, mx, my, vx, vy = x0, y0, 0., 0., 0., 0.; path = [(x, y)]\n    for t in range(1, n+1):\n        gx, gy = grad_f(x, y)\n        mx = b1*mx+(1-b1)*gx;  my = b1*my+(1-b1)*gy\n        vx = b2*vx+(1-b2)*gx**2; vy = b2*vy+(1-b2)*gy**2\n        mxh = mx/(1-b1**t); myh = my/(1-b1**t)\n        vxh = vx/(1-b2**t); vyh = vy/(1-b2**t)\n        x -= lr*mxh/(np.sqrt(vxh)+eps); y -= lr*myh/(np.sqrt(vyh)+eps)\n        path.append((x, y))\n    return path\n\nx0, y0, n_steps = 2.0, 2.0, 60\npaths = {\n    'SGD (lr=0.05)':        run_sgd(x0, y0, 0.05, n_steps),\n    'Momentum (β=0.9)':     run_momentum(x0, y0, 0.05, 0.9, n_steps),\n    'RMSProp':              run_rmsprop(x0, y0, 0.1, 0.9, 1e-8, n_steps),\n    'Adam':                 run_adam(x0, y0, 0.3, 0.9, 0.999, 1e-8, n_steps),\n}\n\nxr = np.linspace(-2.5, 2.5, 300); yr = np.linspace(-2.5, 2.5, 300)\nXg, Yg = np.meshgrid(xr, yr); Zg = f(Xg, Yg)\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\ncolors = ['steelblue', 'tomato', 'seagreen', 'darkorange']\nlevels = [0.5, 2, 5, 10, 20, 40]\n\n# 궤적 그림\nfor ax_i, (pair, title) in enumerate([\n    ([0,1], 'SGD vs Momentum'),\n    ([2,3], 'RMSProp vs Adam'),\n]):\n    ax = axes[ax_i]\n    cs = ax.contour(Xg, Yg, Zg, levels=levels, cmap='Blues', alpha=0.6)\n    ax.clabel(cs, fmt='%.0f', fontsize=8)\n    ax.plot(0, 0, 'r*', ms=15, zorder=10, label='최솟값')\n    for i in pair:\n        name = list(paths.keys())[i]\n        pts = paths[name]\n        xs, ys = zip(*pts)\n        ax.plot(xs, ys, 'o-', color=colors[i], ms=3, lw=1.5, label=name, alpha=0.85)\n        ax.plot(xs[0], ys[0], 's', color=colors[i], ms=10, zorder=5)\n    ax.set_title(title); ax.legend(fontsize=9)\n    ax.set_xlabel('x'); ax.set_ylabel('y')\n\n# 수렴 속도 비교 (로그 스케일)\nax = axes[2]\nfor (name, path), color in zip(paths.items(), colors):\n    losses = [f(x, y) for x, y in path]\n    ax.semilogy(losses, color=color, lw=2, label=name)\nax.set_title('수렴 속도 (로그 스케일)')\nax.set_xlabel('스텝'); ax.set_ylabel('f(x,y)'); ax.legend(fontsize=8)\n\nplt.suptitle('최적화 궤적 비교: f(x,y) = x² + 10y²', fontsize=12)\nplt.tight_layout(); plt.show()\n\nprint('=== 최종 손실 비교 ===')\nfor name, path in paths.items():\n    print(f'  {name:<20}: f = {f(*path[-1]):.6f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code2",
   "metadata": {},
   "outputs": [],
   "source": "# Digits 데이터셋 준비\ndigits = load_digits()\nX = digits.data.astype(np.float32)\ny = digits.target\n\nX_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\nscaler = StandardScaler()\nX_tr_s = scaler.fit_transform(X_tr).astype(np.float32)\nX_te_s = scaler.transform(X_te).astype(np.float32)\n\nX_tr_t = torch.tensor(X_tr_s)\ny_tr_t = torch.tensor(y_tr, dtype=torch.long)\nX_te_t = torch.tensor(X_te_s)\ny_te_t = torch.tensor(y_te, dtype=torch.long)\n\ntrain_ds = TensorDataset(X_tr_t, y_tr_t)\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n\nprint('=== Digits 데이터셋 ===')\nprint(f'  총 샘플: {len(X):,}개')\nprint(f'  특성 수: {X.shape[1]} (8×8 픽셀 → 64차원)')\nprint(f'  클래스: {list(digits.target_names)}  (10개)')\nprint(f'  Train  : {len(X_tr)}개  |  Test: {len(X_te)}개')\n\n# 샘플 시각화\nfig, axes = plt.subplots(2, 10, figsize=(14, 3))\nfor d in range(10):\n    idx  = np.where(y == d)[0][0]\n    idx2 = np.where(y == d)[0][1]\n    axes[0, d].imshow(digits.images[idx],  cmap='gray_r'); axes[0, d].set_title(str(d), fontsize=10)\n    axes[1, d].imshow(digits.images[idx2], cmap='gray_r')\n    for r in range(2): axes[r, d].axis('off')\nplt.suptitle('Digits 샘플 (클래스별 2개)', fontsize=11)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code3",
   "metadata": {},
   "outputs": [],
   "source": "# MLP 클래스 및 학습 함수 (이 셀은 이후 모든 실험에서 공유됩니다)\n\nclass MLP(nn.Module):\n    \"\"\"배치 정규화, 레이어 정규화, 드롭아웃을 지원하는 MLP\"\"\"\n\n    def __init__(self, input_dim, hidden_dims, output_dim,\n                 dropout=0.0, batch_norm=False, layer_norm=False):\n        super().__init__()\n        layers = []\n        prev = input_dim\n        for h in hidden_dims:\n            layers.append(nn.Linear(prev, h))\n            if batch_norm:\n                layers.append(nn.BatchNorm1d(h))\n            elif layer_norm:\n                layers.append(nn.LayerNorm(h))\n            layers.append(nn.ReLU())\n            if dropout > 0:\n                layers.append(nn.Dropout(dropout))\n            prev = h\n        layers.append(nn.Linear(prev, output_dim))\n        self.net = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef train_model(model, loader, X_val, y_val,\n                n_epochs=100, lr=0.001, optimizer_type='adam',\n                weight_decay=0.0, l1_lambda=0.0,\n                scheduler_type=None, verbose=True):\n    \"\"\"\n    optimizer_type: 'sgd', 'momentum', 'rmsprop', 'adam'\n    scheduler_type: None, 'step', 'cosine', 'plateau', 'exp'\n    \"\"\"\n    criterion = nn.CrossEntropyLoss()\n\n    opt_map = {\n        'sgd':      lambda: optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay),\n        'momentum': lambda: optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay),\n        'rmsprop':  lambda: optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay),\n        'adam':     lambda: optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay),\n    }\n    optimizer = opt_map[optimizer_type]()\n\n    scheduler = None\n    if scheduler_type == 'step':\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n    elif scheduler_type == 'cosine':\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n    elif scheduler_type == 'plateau':\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n    elif scheduler_type == 'exp':\n        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n\n    train_losses, val_losses, train_accs, val_accs, lr_hist = [], [], [], [], []\n\n    for epoch in range(n_epochs):\n        model.train()\n        ep_loss, correct, total = 0., 0, 0\n        for Xb, yb in loader:\n            optimizer.zero_grad()\n            logits = model(Xb)\n            loss = criterion(logits, yb)\n            # L1 패널티 수동 추가\n            if l1_lambda > 0:\n                l1 = sum(p.abs().sum() for p in model.parameters())\n                loss = loss + l1_lambda * l1\n            loss.backward()\n            optimizer.step()\n            ep_loss  += loss.item() * len(Xb)\n            correct  += (logits.argmax(1) == yb).sum().item()\n            total    += len(yb)\n\n        train_losses.append(ep_loss / total)\n        train_accs.append(correct / total)\n        lr_hist.append(optimizer.param_groups[0]['lr'])\n\n        model.eval()\n        with torch.no_grad():\n            lv = model(X_val)\n            val_loss = criterion(lv, y_val).item()\n            val_acc  = (lv.argmax(1) == y_val).float().mean().item()\n        val_losses.append(val_loss); val_accs.append(val_acc)\n\n        if scheduler is not None:\n            scheduler.step(val_loss) if scheduler_type == 'plateau' else scheduler.step()\n\n        if verbose and (epoch + 1) % 25 == 0:\n            print(f'Epoch {epoch+1:3d}/{n_epochs} | '\n                  f'Train {train_losses[-1]:.4f}/{train_accs[-1]:.4f} | '\n                  f'Val {val_loss:.4f}/{val_acc:.4f}')\n\n    return train_losses, val_losses, train_accs, val_accs, lr_hist\n\n\n# 모델 확인\ndemo = MLP(64, [128, 64], 10)\nprint('=== MLP 구조 (64 → 128 → 64 → 10) ===')\nprint(demo)\nprint(f'\\n총 파라미터: {sum(p.numel() for p in demo.parameters()):,}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code4",
   "metadata": {},
   "outputs": [],
   "source": "# 4가지 옵티마이저 비교 (Digits 10-class Classification)\nopt_configs = [\n    ('SGD (lr=0.01)',      'sgd',      0.01),\n    ('Momentum (β=0.9)',   'momentum', 0.01),\n    ('RMSProp (lr=0.001)', 'rmsprop',  0.001),\n    ('Adam (lr=0.001)',    'adam',     0.001),\n]\ncolors_opt = ['steelblue', 'tomato', 'seagreen', 'darkorange']\n\nopt_results = {}\nprint('=== 옵티마이저 비교 (100 에포크) ===\\n')\nfor name, opt_type, lr in opt_configs:\n    torch.manual_seed(42)\n    m = MLP(64, [128, 64], 10)\n    t_l, v_l, t_a, v_a, _ = train_model(\n        m, train_loader, X_te_t, y_te_t,\n        n_epochs=100, lr=lr, optimizer_type=opt_type, verbose=False\n    )\n    opt_results[name] = (t_l, v_l, t_a, v_a)\n    print(f'{name:<25}: Val Acc={v_a[-1]:.4f}  Val Loss={v_l[-1]:.4f}')\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor (name, (_, v_l, _, v_a)), color in zip(opt_results.items(), colors_opt):\n    axes[0].plot(v_l, color=color, lw=2, label=name)\n    axes[1].plot(v_a, color=color, lw=2, label=f'{name} ({v_a[-1]:.4f})')\n\nfor ax, title, ylabel in [\n    (axes[0], '옵티마이저별 Val Loss',     'CrossEntropy Loss'),\n    (axes[1], '옵티마이저별 Val Accuracy', 'Accuracy'),\n]:\n    ax.set_title(title); ax.set_xlabel('에포크')\n    ax.set_ylabel(ylabel); ax.legend(fontsize=9)\naxes[1].set_ylim(0.5, 1.02)\n\nplt.suptitle('옵티마이저 비교 (Digits)', fontsize=12)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md",
   "metadata": {},
   "source": "---\n## Part 2. 정규화 (Regularization)\n\n### 2-1. 왜 정규화가 필요한가?\n\n모델이 너무 크거나 학습 데이터가 적으면 **과적합(Overfitting)** 이 발생합니다.\n정규화는 모델의 복잡도를 제한하여 **일반화(Generalization) 성능**을 높입니다.\n\n### 2-2. 주요 정규화 기법\n\n| 기법 | 설명 | PyTorch |\n|---|---|---|\n| **L2 (Weight Decay)** | $L_{\\text{total}} = L + \\lambda \\sum w^2$ | `optimizer(..., weight_decay=λ)` |\n| **L1** | $L_{\\text{total}} = L + \\lambda \\sum |w|$ | 직접 구현 필요 |\n| **Dropout** | 학습 시 뉴런을 확률 $p$로 무작위 비활성화 | `nn.Dropout(p)` |\n\n**Dropout 핵심:**\n- **학습 시**: 각 뉴런을 확률 $p$로 0으로 만들고, 남은 출력을 $\\frac{1}{1-p}$로 스케일\n- **추론 시**: 모든 뉴런을 사용 (`model.eval()` 호출 시 자동 처리)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code1",
   "metadata": {},
   "outputs": [],
   "source": "# 과적합 시나리오: 작은 학습 데이터 + 큰 모델\nnp.random.seed(42)\nsmall_idx = np.random.choice(len(X_tr_t), 150, replace=False)\nX_small_t = X_tr_t[small_idx]\ny_small_t = y_tr_t[small_idx]\n\nsmall_ds     = TensorDataset(X_small_t, y_small_t)\nsmall_loader = DataLoader(small_ds, batch_size=32, shuffle=True)\n\ntorch.manual_seed(42)\nmodel_overfit = MLP(64, [256, 256, 128], 10)\nprint(f'=== 과적합 시나리오: 150개 학습 샘플, 큰 모델 ===')\nprint(f'모델 파라미터: {sum(p.numel() for p in model_overfit.parameters()):,}개')\n\nt_l_ov, v_l_ov, t_a_ov, v_a_ov, _ = train_model(\n    model_overfit, small_loader, X_te_t, y_te_t,\n    n_epochs=200, lr=0.001, verbose=False\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 4))\nep = range(1, 201)\n\naxes[0].plot(ep, t_l_ov, 'b-', lw=2, label=f'Train Loss')\naxes[0].plot(ep, v_l_ov, 'r-', lw=2, label=f'Val Loss')\naxes[0].set_title('과적합: Loss 곡선'); axes[0].set_xlabel('에포크'); axes[0].set_ylabel('Loss')\naxes[0].legend()\n\naxes[1].plot(ep, t_a_ov, 'b-', lw=2, label=f'Train Acc ({t_a_ov[-1]:.4f})')\naxes[1].plot(ep, v_a_ov, 'r-', lw=2, label=f'Val Acc   ({v_a_ov[-1]:.4f})')\naxes[1].set_title('과적합: Accuracy 곡선'); axes[1].set_xlabel('에포크'); axes[1].set_ylabel('Accuracy')\naxes[1].legend()\n\nplt.suptitle('과적합(Overfitting): Train ↑, Val ↓ — 일반화 실패!', fontsize=12)\nplt.tight_layout(); plt.show()\n\ngap = t_a_ov[-1] - v_a_ov[-1]\nprint(f'\\nTrain Acc  : {t_a_ov[-1]:.4f}')\nprint(f'Val   Acc  : {v_a_ov[-1]:.4f}')\nprint(f'일반화 Gap : {gap:.4f}  (클수록 과적합 심각)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code2",
   "metadata": {},
   "outputs": [],
   "source": "# 정규화 기법 비교 (동일한 작은 데이터셋, 큰 모델)\nreg_configs = [\n    ('정규화 없음',        dict(dropout=0.0), 0.0,  0.0),\n    ('L2 (wd=0.01)',      dict(dropout=0.0), 0.01, 0.0),\n    ('L1 (λ=1e-4)',       dict(dropout=0.0), 0.0,  1e-4),\n    ('Dropout (p=0.4)',   dict(dropout=0.4), 0.0,  0.0),\n    ('L2 + Dropout',     dict(dropout=0.4), 0.01, 0.0),\n]\ncolors_reg = ['gray', 'steelblue', 'purple', 'tomato', 'seagreen']\n\nreg_results = {}\nprint('=== 정규화 기법 비교 ===\\n')\nprint(f'{\"기법\":<20} {\"Train Acc\":>10} {\"Val Acc\":>10} {\"Gap\":>8}')\nprint('-' * 52)\n\nfor name, model_kw, wd, l1 in reg_configs:\n    torch.manual_seed(42)\n    m = MLP(64, [256, 256, 128], 10, **model_kw)\n    t_l, v_l, t_a, v_a, _ = train_model(\n        m, small_loader, X_te_t, y_te_t,\n        n_epochs=200, lr=0.001, weight_decay=wd, l1_lambda=l1, verbose=False\n    )\n    reg_results[name] = (t_l, v_l, t_a, v_a)\n    gap = t_a[-1] - v_a[-1]\n    print(f'{name:<20} {t_a[-1]:>10.4f} {v_a[-1]:>10.4f} {gap:>8.4f}')\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nep = range(1, 201)\nfor (name, (_, v_l, t_a, v_a)), color in zip(reg_results.items(), colors_reg):\n    axes[0].plot(ep, v_l, color=color, lw=2, label=name)\n    axes[1].plot(ep, v_a, color=color, lw=2, label=f'{name} ({v_a[-1]:.4f})')\n\nfor ax, title, ylabel in [\n    (axes[0], 'Val Loss — 정규화 효과',     'Loss'),\n    (axes[1], 'Val Accuracy — 정규화 효과', 'Accuracy'),\n]:\n    ax.set_title(title); ax.set_xlabel('에포크')\n    ax.set_ylabel(ylabel); ax.legend(fontsize=8)\n\nplt.suptitle('정규화 기법 비교 (과적합 환경, 150개 학습 샘플)', fontsize=12)\nplt.tight_layout(); plt.show()\n\n# Dropout 동작 확인 (train vs eval 모드)\nmodel_test = MLP(64, [8], 10, dropout=0.5)\nx_test = torch.randn(1, 64)\nmodel_test.train()\nout_train = model_test(x_test).detach()\nmodel_test.eval()\nout_eval  = model_test(x_test).detach()\nprint('\\nDropout 동작 확인 (출력 최댓값):')\nprint(f'  train 모드 (Dropout 활성):  {out_train.max().item():.4f}')\nprint(f'  eval  모드 (Dropout 비활성): {out_eval.max().item():.4f}')"
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md",
   "metadata": {},
   "source": "---\n## Part 3. 배치 정규화 & 레이어 정규화\n\n### 3-1. 배치 정규화 (Batch Normalization)\n\n**내부 공변량 이동(Internal Covariate Shift)**: 학습 중 각 층의 입력 분포가 계속 변하는 현상.\n이로 인해 학습 속도가 느려지고 높은 학습률 사용이 어렵습니다.\n\n**BN 해결책:** 각 미니배치에서 정규화 수행\n\n$$\\hat{x} = \\frac{x - \\mu_B}{\\sqrt{\\sigma_B^2 + \\varepsilon}}, \\quad y = \\gamma \\hat{x} + \\beta$$\n\n| 항목 | 내용 |\n|---|---|\n| $\\mu_B, \\sigma_B^2$ | 미니배치의 평균과 분산 |\n| $\\gamma, \\beta$ | 학습 가능한 스케일 & 시프트 파라미터 |\n| **학습 시** | 미니배치 통계 사용 |\n| **추론 시** | 학습 중 누적한 이동 평균 통계 사용 |\n\n### 3-2. 레이어 정규화 (Layer Normalization)\n\nBN은 배치 전체로 정규화하지만, **LayerNorm** 은 샘플 하나의 특성 차원으로 정규화합니다.\n배치 크기가 작거나 RNN/Transformer에서 주로 사용됩니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code1",
   "metadata": {},
   "outputs": [],
   "source": "# BatchNorm vs No-BN: 수렴 속도 및 안정성 비교\nbn_configs = [\n    ('No BN  (lr=0.01)',  False, False, 0.01),\n    ('No BN  (lr=0.001)', False, False, 0.001),\n    ('BatchNorm (lr=0.01)',  True,  False, 0.01),\n    ('BatchNorm (lr=0.001)', True,  False, 0.001),\n]\ncolors_bn = ['steelblue', 'steelblue', 'tomato', 'tomato']\nstyles_bn  = ['--', '-', '--', '-']\n\nbn_results = {}\nprint('=== BatchNorm 효과 비교 ===\\n')\nfor name, use_bn, use_ln, lr in bn_configs:\n    torch.manual_seed(42)\n    m = MLP(64, [128, 64], 10, batch_norm=use_bn, layer_norm=use_ln)\n    n_params = sum(p.numel() for p in m.parameters())\n    t_l, v_l, t_a, v_a, _ = train_model(\n        m, train_loader, X_te_t, y_te_t,\n        n_epochs=100, lr=lr, verbose=False\n    )\n    bn_results[name] = (v_l, v_a)\n    print(f'{name:<26}  params={n_params:,}  Val Acc={v_a[-1]:.4f}')\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\nfor (name, (v_l, v_a)), color, ls in zip(bn_results.items(), colors_bn, styles_bn):\n    label_acc = f'{name} ({v_a[-1]:.4f})'\n    axes[0].plot(v_l, color=color, lw=2, ls=ls, label=name)\n    axes[1].plot(v_a, color=color, lw=2, ls=ls, label=label_acc)\n\nfor ax, title, ylabel in [\n    (axes[0], 'BatchNorm 효과: Val Loss',     'Loss'),\n    (axes[1], 'BatchNorm 효과: Val Accuracy', 'Accuracy'),\n]:\n    ax.set_title(title); ax.set_xlabel('에포크')\n    ax.set_ylabel(ylabel); ax.legend(fontsize=9)\n\nplt.suptitle('Batch Normalization: 더 높은 lr에서도 안정적 학습!', fontsize=12)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code2",
   "metadata": {},
   "outputs": [],
   "source": "# BN vs LayerNorm vs No-Norm 비교\nnorm_configs = [\n    ('No Norm',    False, False),\n    ('BatchNorm',  True,  False),\n    ('LayerNorm',  False, True),\n]\ncolors_norm = ['steelblue', 'tomato', 'seagreen']\n\nnorm_results = {}\nprint('=== BN vs LayerNorm vs No-Norm (lr=0.01) ===\\n')\nfor name, bn, ln in norm_configs:\n    torch.manual_seed(42)\n    m = MLP(64, [128, 64], 10, batch_norm=bn, layer_norm=ln)\n    t_l, v_l, t_a, v_a, _ = train_model(\n        m, train_loader, X_te_t, y_te_t,\n        n_epochs=100, lr=0.01, verbose=False\n    )\n    norm_results[name] = (v_l, v_a)\n    print(f'{name:<12}: Val Acc={v_a[-1]:.4f}  최고 Val Acc={max(v_a):.4f}')\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 4))\nfor (name, (v_l, v_a)), color in zip(norm_results.items(), colors_norm):\n    axes[0].plot(v_l, color=color, lw=2, label=name)\n    axes[1].plot(v_a, color=color, lw=2, label=f'{name} ({v_a[-1]:.4f})')\n\nfor ax, title, ylabel in [\n    (axes[0], '정규화별 Val Loss',     'Loss'),\n    (axes[1], '정규화별 Val Accuracy', 'Accuracy'),\n]:\n    ax.set_title(title); ax.set_xlabel('에포크')\n    ax.set_ylabel(ylabel); ax.legend(fontsize=9)\n\nplt.suptitle('No Norm vs BatchNorm vs LayerNorm (lr=0.01)', fontsize=12)\nplt.tight_layout(); plt.show()\n\nprint('\\n[참고]')\nprint('  BatchNorm: 배치 차원으로 정규화 → CNN, MLP에 적합')\nprint('  LayerNorm: 특성 차원으로 정규화 → RNN, Transformer에 적합')"
  },
  {
   "cell_type": "markdown",
   "id": "c-p4-md",
   "metadata": {},
   "source": "---\n## Part 4. 학습률 스케줄링 (Learning Rate Scheduling)\n\n### 왜 학습률을 조정하는가?\n\n- **초기 학습**: 큰 학습률 → 빠른 수렴\n- **후반 학습**: 작은 학습률 → 세밀한 최적화, 진동 방지\n\n| 스케줄러 | 방식 | 특징 |\n|---|---|---|\n| **StepLR** | N 에포크마다 lr × γ | 단순, 예측 가능 |\n| **CosineAnnealingLR** | 코사인 함수로 lr 감소 | 부드러운 감소, warm restart 응용 |\n| **ExponentialLR** | 매 에포크마다 lr × γ | 지수적 감소 |\n| **ReduceLROnPlateau** | Val Loss가 개선되지 않을 때 lr 감소 | 적응형, 실전에서 많이 사용 |\n\n```python\n# 사용 예시\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\nfor epoch in range(n_epochs):\n    # ... 학습 루프 ...\n    scheduler.step()          # 에포크 끝에 호출\n    # ReduceLROnPlateau는: scheduler.step(val_loss)\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code1",
   "metadata": {},
   "outputs": [],
   "source": "# 학습률 스케줄러 시각화 (실제 학습 없이 lr 변화만 확인)\nn_epochs_vis = 100\ninit_lr = 0.01\n\ndummy_p = nn.Parameter(torch.tensor(0.0))  # 더미 파라미터\n\nschedulers_vis = {\n    '고정 lr':            (None, {}),\n    'StepLR (s=30, γ=0.5)': ('step',   {'step_size': 30, 'gamma': 0.5}),\n    'CosineAnnealingLR':   ('cosine', {'T_max': n_epochs_vis}),\n    'ExponentialLR (γ=0.95)': ('exp',  {'gamma': 0.95}),\n}\n\nfig, ax = plt.subplots(figsize=(10, 4))\ncolors_sch = ['gray', 'steelblue', 'tomato', 'seagreen']\n\nfor (name, (sch_type, sch_kw)), color in zip(schedulers_vis.items(), colors_sch):\n    opt_v = optim.SGD([dummy_p], lr=init_lr)\n    if sch_type == 'step':\n        sch = torch.optim.lr_scheduler.StepLR(opt_v, **sch_kw)\n    elif sch_type == 'cosine':\n        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt_v, **sch_kw)\n    elif sch_type == 'exp':\n        sch = torch.optim.lr_scheduler.ExponentialLR(opt_v, **sch_kw)\n    else:\n        sch = None\n    lrs = []\n    for ep in range(n_epochs_vis):\n        lrs.append(opt_v.param_groups[0]['lr'])\n        if sch: sch.step()\n    ax.plot(range(1, n_epochs_vis+1), lrs, color=color, lw=2, label=name)\n\nax.set_title(f'학습률 스케줄러별 lr 변화 (초기 lr={init_lr})')\nax.set_xlabel('에포크'); ax.set_ylabel('Learning Rate')\nax.legend()\nplt.tight_layout(); plt.show()\n\nprint('=== 학습률 핵심 포인트 ===')\nprint('  - 너무 크면: 발산(loss 폭발)')\nprint('  - 너무 작으면: 수렴 매우 느림')\nprint('  - 스케줄링: 초반 크게 → 후반 작게 = 속도 + 정밀도')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code2",
   "metadata": {},
   "outputs": [],
   "source": "# 스케줄러 학습 비교\nsch_configs = [\n    ('Adam (고정 lr=0.001)',    'adam', None,     0.001),\n    ('Adam + StepLR',           'adam', 'step',   0.01),\n    ('Adam + CosineAnneal',     'adam', 'cosine', 0.01),\n    ('Adam + ExponentialLR',    'adam', 'exp',    0.01),\n]\ncolors_sch2 = ['gray', 'steelblue', 'tomato', 'seagreen']\n\nsch_results = {}\nprint('=== 학습률 스케줄링 비교 (100 에포크) ===\\n')\nfor name, opt_type, sch_type, lr in sch_configs:\n    torch.manual_seed(42)\n    m = MLP(64, [128, 64], 10)\n    t_l, v_l, t_a, v_a, lr_hist = train_model(\n        m, train_loader, X_te_t, y_te_t,\n        n_epochs=100, lr=lr, optimizer_type=opt_type,\n        scheduler_type=sch_type, verbose=False\n    )\n    sch_results[name] = (v_a, lr_hist)\n    print(f'{name:<30}: 최종 Val Acc={v_a[-1]:.4f}  최고 Val Acc={max(v_a):.4f}')\n\nfig, axes = plt.subplots(1, 2, figsize=(13, 4))\nfor (name, (v_a, lr_hist)), color in zip(sch_results.items(), colors_sch2):\n    axes[0].plot(range(1, 101), v_a,     color=color, lw=2, label=f'{name} ({v_a[-1]:.4f})')\n    axes[1].plot(range(1, 101), lr_hist, color=color, lw=2, label=name)\n\naxes[0].set_title('스케줄러별 Val Accuracy')\naxes[0].set_xlabel('에포크'); axes[0].set_ylabel('Accuracy')\naxes[0].legend(fontsize=8)\n\naxes[1].set_title('스케줄러별 lr 변화')\naxes[1].set_xlabel('에포크'); axes[1].set_ylabel('Learning Rate')\naxes[1].legend(fontsize=8)\n\nplt.suptitle('학습률 스케줄링 비교', fontsize=12)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md1",
   "metadata": {},
   "source": "---\n## Exercise\n\n### Exercise 1. 정규화 전략 심층 비교\n\n전체 학습 데이터(X_tr_t, y_tr_t)를 사용하여 아래 4가지 설정을 비교하세요.\n\n| 설정 | 내용 |\n|---|---|\n| 기준 | No regularization (dropout=0, weight_decay=0) |\n| A | Dropout p=0.3 |\n| B | L2 weight_decay=0.001 |\n| C | Dropout p=0.3 + L2 weight_decay=0.001 |\n\n**요구사항:**\n- 모델 구조: `hidden_dims=[128, 64]`, `n_epochs=100`, Adam, `lr=0.001`\n- Val Accuracy 학습 곡선 시각화 (4개 선)\n- 최종 Val Accuracy 및 Train Accuracy 출력 (일반화 Gap 포함)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex1",
   "metadata": {},
   "outputs": [],
   "source": "# Exercise 1: 정규화 전략 비교\nconfigs_ex1 = {\n    '기준 (No Reg)':             dict(dropout=0.0, weight_decay=0.0),\n    'A: Dropout p=0.3':          dict(dropout=0.3, weight_decay=0.0),\n    'B: L2 wd=0.001':            dict(dropout=0.0, weight_decay=0.001),\n    'C: Dropout + L2':           dict(dropout=0.3, weight_decay=0.001),\n}\n\nex1_results = {}\n\nfor name, cfg in configs_ex1.items():\n    # Your code here: MLP 생성, train_model 호출, 결과 저장\n    pass\n\n# Your code here: Val Accuracy 학습 곡선 시각화\n\n# Your code here: 최종 Val Acc, Train Acc, Gap 출력"
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md2",
   "metadata": {},
   "source": "### Exercise 2. BatchNorm + Dropout 조합 최적화\n\n아래 4가지 조합에서 최적의 설정을 찾으세요.\n\n| 모델 | batch_norm | dropout |\n|---|---|---|\n| Vanilla | False | 0.0 |\n| BN only | True | 0.0 |\n| Dropout only | False | 0.3 |\n| BN + Dropout | True | 0.3 |\n\n**요구사항:**\n- 구조: `hidden_dims=[256, 128, 64]`, `n_epochs=100`, Adam, `lr=0.01`\n- Val Loss + Val Accuracy 학습 곡선 시각화\n- 최종 성능 표 출력 (Val Acc, 파라미터 수 포함)\n\n**힌트:** BatchNorm 레이어도 파라미터를 추가합니다!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex2",
   "metadata": {},
   "outputs": [],
   "source": "# Exercise 2: BN + Dropout 조합\nbn_drop_configs = {\n    'Vanilla':      dict(batch_norm=False, dropout=0.0),\n    'BN only':      dict(batch_norm=True,  dropout=0.0),\n    'Dropout only': dict(batch_norm=False, dropout=0.3),\n    'BN + Dropout': dict(batch_norm=True,  dropout=0.3),\n}\n\nex2_results = {}\n\nfor name, cfg in bn_drop_configs.items():\n    # Your code here: MLP 생성 (hidden_dims=[256, 128, 64], output_dim=10, lr=0.01)\n\n    # Your code here: train_model 호출, 결과 저장\n    pass\n\n# Your code here: Val Loss, Val Accuracy 곡선 시각화\n\n# Your code here: 최종 성능 표 (Val Acc, 파라미터 수)"
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md3",
   "metadata": {},
   "source": "### Exercise 3. (도전) ReduceLROnPlateau + Early Stopping\n\n**Early Stopping**: 검증 손실이 일정 에포크 동안 개선되지 않으면 학습을 조기 종료합니다.\n\n```\n최고 val_loss 갱신 시 → 모델 저장, 카운터 초기화\n개선 없을 때         → 카운터 +1\n카운터 ≥ patience   → 학습 종료\n```\n\n**요구사항:**\n1. `train_with_early_stopping()` 함수 구현\n   - `ReduceLROnPlateau` 스케줄러 사용 (patience=5, factor=0.5)\n   - Early stopping: patience=15\n2. 모델: `MLP(64, [128, 64], 10)`, Adam, 초기 `lr=0.01`, `max_epochs=300`\n3. 결과 출력: 실제 학습 에포크 수, 최종 Val Acc, lr 변화 곡선\n\n**힌트:**\n```python\nimport copy\nbest_model_state = copy.deepcopy(model.state_dict())  # 모델 상태 저장\nmodel.load_state_dict(best_model_state)                # 최고 상태로 복원\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex3",
   "metadata": {},
   "outputs": [],
   "source": "import copy\n\ndef train_with_early_stopping(model, loader, X_val, y_val,\n                               max_epochs=300, lr=0.01, patience=15):\n    \"\"\"\n    ReduceLROnPlateau + Early Stopping 구현\n    Returns: val_accs, lr_history, actual_epochs\n    \"\"\"\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    # Your code here: ReduceLROnPlateau 스케줄러 생성 (patience=5, factor=0.5)\n\n    best_val_loss = float('inf')\n    patience_counter = 0\n    best_state = None\n\n    val_accs  = []\n    lr_history = []\n\n    for epoch in range(max_epochs):\n        # Your code here: 학습 루프 (train_loader 사용)\n\n        # Your code here: 검증 (val_loss, val_acc 계산)\n\n        # Your code here: val_accs, lr_history 기록\n\n        # Your code here: scheduler.step(val_loss)\n\n        # Your code here: Early stopping 체크\n        #   - val_loss < best_val_loss → best 갱신, 카운터 초기화, 모델 저장\n        #   - 그렇지 않으면 카운터 증가 → patience 초과 시 break\n        pass\n\n    # Your code here: 최고 모델 복원\n\n    return val_accs, lr_history, epoch + 1\n\n\n# Your code here: 실험 실행 및 결과 시각화\ntorch.manual_seed(42)\nmodel_es = MLP(64, [128, 64], 10)\n\n# val_accs, lr_history, actual_ep = train_with_early_stopping(\n#     model_es, train_loader, X_te_t, y_te_t, max_epochs=300, lr=0.01, patience=15\n# )\n# print(f'실제 학습 에포크: {actual_ep} / 300')\n# print(f'최종 Val Accuracy: {val_accs[-1]:.4f}')"
  },
  {
   "cell_type": "markdown",
   "id": "c-summary",
   "metadata": {},
   "source": "---\n## Summary\n\n| 개념 | 핵심 내용 |\n|---|---|\n| **SGD** | 기본 경사 하강법, 학습률에 민감, 지그재그 수렴 |\n| **Momentum** | 관성 누적으로 지그재그 감소, 빠른 수렴 |\n| **RMSProp** | 방향별 적응적 학습률, 비정상(non-stationary) 데이터에 강함 |\n| **Adam** | Momentum + RMSProp, 대부분 상황에서 첫 번째 선택 |\n| **L1 규제** | $\\sum|w|$ 패널티, 희소(sparse) 가중치 유도 |\n| **L2 규제** | $\\sum w^2$ 패널티, 가중치를 0 근처로 수축 |\n| **Dropout** | 학습 시 무작위 뉴런 비활성, 앙상블 효과 |\n| **BatchNorm** | 미니배치 정규화, 학습 안정성↑, 높은 lr 허용 |\n| **LayerNorm** | 샘플별 특성 정규화, RNN/Transformer에 적합 |\n| **StepLR** | N 에포크마다 lr × γ, 예측 가능한 감소 |\n| **CosineAnnealingLR** | 코사인 곡선으로 부드러운 감소 |\n| **ReduceLROnPlateau** | Val Loss 정체 시 자동 감소, 실전에서 많이 사용 |\n| **Early Stopping** | Val Loss 개선 없으면 조기 종료, 과적합 방지 |\n\n---\n\n**다음 강의 (Week 12):** CNN — 합성곱 신경망, 풀링, 이미지 분류"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}