{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c-title",
   "metadata": {},
   "source": [
    "# Lab 07 — Tree-based Models\n",
    "\n",
    "\n",
    "> **주제:** 결정 트리부터 랜덤 포레스트, 앙상블 비교까지\n",
    "\n",
    "---\n",
    "\n",
    "## 학습 목표\n",
    "\n",
    "| # | 목표 | \n",
    "|---|---| \n",
    "| 1 | 분할 기준(Gini / Entropy) 이해 및 시각화 |  \n",
    "| 2 | Tic-Tac-Toe 데이터로 결정 트리 학습 · 시각화 · 가지치기 |  \n",
    "| 3 | 랜덤 포레스트 — 배깅 개념 + 특성 중요도 |  \n",
    "| 4 | 앙상블 비교 (Bagging vs Boosting) |  \n",
    "| 5 | Exercise |  \n",
    "\n",
    "---\n",
    "\n",
    "**데이터셋:** UCI Tic-Tac-Toe Endgame — 틱택토 보드 상태로 X 승리 여부 이진 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, BaggingClassifier,\n",
    "    GradientBoostingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# 한글 폰트\n",
    "_fp = '/System/Library/Fonts/AppleGothic.ttf'\n",
    "fm.fontManager.addfont(_fp)\n",
    "plt.rcParams['font.family'] = fm.FontProperties(fname=_fp).get_name()\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "print('설정 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p1-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1. 결정 트리 — 분할 기준\n",
    "\n",
    "### 1-1. 결정 트리란?\n",
    "\n",
    "**결정 트리(Decision Tree)** 는 데이터를 반복적으로 분할(split)해서 클래스를 예측합니다.\n",
    "\n",
    "```\n",
    "                 [꽃잎 길이 ≤ 2.5?]\n",
    "                 /              \\\n",
    "            예(Yes)            아니오(No)\n",
    "           [Setosa]      [꽃잎 너비 ≤ 1.8?]\n",
    "                          /           \\\n",
    "                   [Versicolor]    [Virginica]\n",
    "```\n",
    "\n",
    "각 노드에서 **어떤 특성으로 분할할지** 결정하는 기준:\n",
    "\n",
    "| 기준 | 수식 | 특징 |\n",
    "|---|---|---|\n",
    "| **Gini 불순도** | $1 - \\sum_k p_k^2$ | 빠름, sklearn 기본값 |\n",
    "| **엔트로피** | $-\\sum_k p_k \\log_2 p_k$ | 정보 이론 기반, 약간 더 균형적 |\n",
    "\n",
    "> **목표:** 분할 후 자식 노드들의 불순도 가중합을 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p1-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini vs Entropy 시각화\n",
    "p = np.linspace(1e-6, 1 - 1e-6, 300)   # 클래스 1의 비율\n",
    "\n",
    "gini    = 2 * p * (1 - p)               # 이진 Gini: 1 - p^2 - (1-p)^2 = 2p(1-p)\n",
    "entropy = -(p*np.log2(p) + (1-p)*np.log2(1-p))\n",
    "error   = 1 - np.maximum(p, 1-p)        # 오분류율\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "axes[0].plot(p, gini,    color='steelblue', lw=2.5, label='Gini 불순도')\n",
    "axes[0].plot(p, entropy, color='tomato',    lw=2.5, label='Entropy (÷2 정규화)')\n",
    "axes[0].plot(p, error,   color='seagreen',  lw=2.0, linestyle='--', label='오분류율')\n",
    "axes[0].axvline(0.5, color='gray', linestyle=':', lw=1.5)\n",
    "axes[0].set_title('이진 분류에서 불순도 지표 비교')\n",
    "axes[0].set_xlabel('클래스 1 비율 (p)')\n",
    "axes[0].set_ylabel('불순도 / 오분류율')\n",
    "axes[0].legend()\n",
    "\n",
    "# 분할 전후 불순도 감소 예시\n",
    "# 부모: [40 A, 40 B]  →  자식1: [30 A, 10 B], 자식2: [10 A, 30 B]\n",
    "def gini_impurity(counts):\n",
    "    total = sum(counts)\n",
    "    return 1 - sum((c/total)**2 for c in counts)\n",
    "\n",
    "splits = [\n",
    "    ('나쁜 분할',   [40, 40], [20, 20], [20, 20]),\n",
    "    ('보통 분할',   [40, 40], [30, 10], [10, 30]),\n",
    "    ('좋은 분할',   [40, 40], [38,  2], [ 2, 38]),\n",
    "    ('완벽한 분할', [40, 40], [40,  0], [ 0, 40]),\n",
    "]\n",
    "\n",
    "labels_sp, ig_vals = [], []\n",
    "for name, parent, child1, child2 in splits:\n",
    "    g_parent = gini_impurity(parent)\n",
    "    n_tot    = sum(parent)\n",
    "    n1, n2   = sum(child1), sum(child2)\n",
    "    g_after  = (n1/n_tot)*gini_impurity(child1) + (n2/n_tot)*gini_impurity(child2)\n",
    "    ig_vals.append(g_parent - g_after)\n",
    "    labels_sp.append(name)\n",
    "\n",
    "colors_sp = ['tomato', 'orange', 'steelblue', 'seagreen']\n",
    "bars = axes[1].barh(labels_sp, ig_vals, color=colors_sp, edgecolor='k', alpha=0.85)\n",
    "for bar, val in zip(bars, ig_vals):\n",
    "    axes[1].text(val + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{val:.3f}', va='center', fontsize=10)\n",
    "axes[1].set_title('분할 방식에 따른 정보 이득(Information Gain)')\n",
    "axes[1].set_xlabel('Gini 정보 이득 (클수록 좋은 분할)')\n",
    "axes[1].set_xlim(0, 0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('순수 노드(한 클래스만 있을 때): Gini=0, Entropy=0  → 최적 상태')\n",
    "print('완전 혼합(50:50일 때):         Gini=0.5, Entropy=1 → 최악 상태')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2. 결정 트리 실습 — Tic-Tac-Toe Endgame\n",
    "\n",
    "### 2-1. 데이터셋 소개\n",
    "\n",
    "| 속성 | 설명 |\n",
    "|---|---|\n",
    "| 특성 수 | 9개 (보드 9칸, 각각 `x` / `o` / `b(blank)`) |\n",
    "| 샘플 수 | 958개 |\n",
    "| 레이블 | `positive` (X 승리) / `negative` (X 미승리) |\n",
    "\n",
    "```\n",
    "보드 위치:\n",
    "  TL | TM | TR\n",
    "  ---+----+---\n",
    "  ML |  C | MR\n",
    "  ---+----+---\n",
    "  BL | BM | BR\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tic-Tac-Toe 데이터 로드\n",
    "try:\n",
    "    ttt = fetch_openml('tic-tac-toe', version=1, as_frame=True, parser='auto')\n",
    "    df  = ttt.frame.copy()\n",
    "    print('OpenML에서 로드 성공')\n",
    "except Exception:\n",
    "    # 네트워크 없을 때: 직접 생성 (996개 유효 보드 상태 중 일부)\n",
    "    import itertools\n",
    "    print('OpenML 실패 → 합성 데이터 사용')\n",
    "    cols  = ['TL','TM','TR','ML','C','MR','BL','BM','BR']\n",
    "    lines = [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]\n",
    "    rows, labels = [], []\n",
    "    for combo in itertools.product(['x','o','b'], repeat=9):\n",
    "        board = list(combo)\n",
    "        x_wins = any(all(board[i]=='x' for i in line) for line in lines)\n",
    "        rows.append(board)\n",
    "        labels.append('positive' if x_wins else 'negative')\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    df['class'] = labels\n",
    "    df = df.sample(958, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 컬럼명 정리\n",
    "feature_cols = [c for c in df.columns if c != 'class']\n",
    "print(f'특성 컬럼: {feature_cols}')\n",
    "print(f'샘플 수  : {len(df)}')\n",
    "print(f'클래스 분포:\\n{df[\"class\"].value_counts()}\\n')\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 → 수치 인코딩  (x=2, o=1, b=0)\n",
    "enc = OrdinalEncoder(categories=[['b','o','x']]*9)\n",
    "X   = enc.fit_transform(df[feature_cols]).astype(np.float32)\n",
    "y   = (df['class'] == 'positive').astype(int).values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train: {len(X_tr)}  |  Test: {len(X_te)}')\n",
    "print(f'클래스 비율 (Train) — positive: {y_tr.mean():.2%}  negative: {1-y_tr.mean():.2%}')\n",
    "\n",
    "# 보드 시각화 함수\n",
    "def draw_board(sample_row, ax, title=''):\n",
    "    board = enc.inverse_transform([sample_row])[0]\n",
    "    sym_map = {'x': 'X', 'o': 'O', 'b': ''}\n",
    "    colors  = {'x': '#aed6f1', 'o': '#f9caca', 'b': '#f5f5f5'}\n",
    "    for i, sym in enumerate(board):\n",
    "        r, c = divmod(i, 3)\n",
    "        ax.add_patch(plt.Rectangle((c, 2-r), 1, 1,\n",
    "                     facecolor=colors[sym], edgecolor='black', lw=1.5))\n",
    "        ax.text(c+0.5, 2-r+0.5, sym_map[sym], ha='center', va='center',\n",
    "                fontsize=18, fontweight='bold',\n",
    "                color='steelblue' if sym=='x' else 'tomato')\n",
    "    ax.set_xlim(0, 3); ax.set_ylim(0, 3)\n",
    "    ax.set_aspect('equal'); ax.axis('off')\n",
    "    ax.set_title(title, fontsize=9)\n",
    "\n",
    "# 대표 샘플 보드 시각화\n",
    "fig, axes = plt.subplots(1, 6, figsize=(13, 2.5))\n",
    "pos_idx = np.where(y_tr == 1)[0][:3]\n",
    "neg_idx = np.where(y_tr == 0)[0][:3]\n",
    "for ax, idx, lbl in zip(axes[:3], pos_idx, ['X 승리']*3):\n",
    "    draw_board(X_tr[idx], ax, title=lbl)\n",
    "for ax, idx, lbl in zip(axes[3:], neg_idx, ['X 미승리']*3):\n",
    "    draw_board(X_tr[idx], ax, title=lbl)\n",
    "plt.suptitle('Tic-Tac-Toe 보드 샘플 (파랑=X, 빨강=O)', y=1.08)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md2",
   "metadata": {},
   "source": [
    "### 2-2. 결정 트리 학습 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 결정 트리 (제한 없음)\n",
    "dt_full = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "dt_full.fit(X_tr, y_tr)\n",
    "\n",
    "print(f'트리 깊이     : {dt_full.get_depth()}')\n",
    "print(f'리프 노드 수  : {dt_full.get_n_leaves()}')\n",
    "print(f'Train Accuracy: {dt_full.score(X_tr, y_tr):.4f}')\n",
    "print(f'Test  Accuracy: {dt_full.score(X_te, y_te):.4f}')\n",
    "\n",
    "# 얕은 트리 시각화 (depth=3)\n",
    "dt_viz = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "dt_viz.fit(X_tr, y_tr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "plot_tree(\n",
    "    dt_viz,\n",
    "    feature_names=feature_cols,\n",
    "    class_names=['미승리', 'X승리'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('결정 트리 시각화 (max_depth=3) — 파란색: X승리, 주황색: 미승리')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nmax_depth=3 트리 Test Accuracy: {dt_viz.score(X_te, y_te):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p2-md3",
   "metadata": {},
   "source": [
    "### 2-3. 가지치기 (Pruning) — 과적합 방지\n",
    "\n",
    "깊은 트리는 훈련 데이터에 **과적합(overfitting)** 됩니다.  \n",
    "`max_depth`, `min_samples_leaf` 등으로 트리 크기를 제한합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p2-code4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth별 train / test 정확도\n",
    "depths      = list(range(1, 20))\n",
    "train_accs  = []\n",
    "test_accs   = []\n",
    "\n",
    "for d in depths:\n",
    "    dt = DecisionTreeClassifier(criterion='gini', max_depth=d, random_state=42)\n",
    "    dt.fit(X_tr, y_tr)\n",
    "    train_accs.append(dt.score(X_tr, y_tr))\n",
    "    test_accs.append(dt.score(X_te, y_te))\n",
    "\n",
    "best_depth  = depths[np.argmax(test_accs)]\n",
    "best_acc    = max(test_accs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "ax.plot(depths, train_accs, 'o-', color='steelblue', lw=2, label='Train Accuracy')\n",
    "ax.plot(depths, test_accs,  's-', color='tomato',    lw=2, label='Test Accuracy')\n",
    "ax.axvline(best_depth, color='seagreen', linestyle='--', lw=2,\n",
    "           label=f'최적 깊이 = {best_depth}  (Test Acc={best_acc:.3f})')\n",
    "ax.fill_between(depths, train_accs, test_accs,\n",
    "                where=[tr > te for tr, te in zip(train_accs, test_accs)],\n",
    "                alpha=0.15, color='tomato', label='과적합 구간')\n",
    "ax.set_title('트리 깊이(max_depth)에 따른 정확도 변화')\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'깊이 제한 없음 → Train: {dt_full.score(X_tr, y_tr):.3f} / Test: {dt_full.score(X_te, y_te):.3f}  ← 과적합!')\n",
    "print(f'최적 깊이({best_depth})    → Train: {train_accs[best_depth-1]:.3f} / Test: {test_accs[best_depth-1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3. 랜덤 포레스트\n",
    "\n",
    "### 3-1. 배깅 (Bagging) 아이디어\n",
    "\n",
    "단일 결정 트리는 **분산(variance)이 높아** 과적합되기 쉽습니다.  \n",
    "**배깅(Bootstrap Aggregating)** 은 여러 트리를 독립적으로 학습시켜 **평균(다수결)** 을 냅니다.\n",
    "\n",
    "```\n",
    "원본 데이터\n",
    "    │\n",
    "    ├─ 부트스트랩 샘플1 → 트리1 → 예측1 ─┐\n",
    "    ├─ 부트스트랩 샘플2 → 트리2 → 예측2 ─┼─→ 다수결 → 최종 예측\n",
    "    └─ 부트스트랩 샘플N → 트리N → 예측N ─┘\n",
    "```\n",
    "\n",
    "**랜덤 포레스트** = 배깅 + **무작위 특성 선택(Feature Subsampling)**\n",
    "- 각 분할 시 전체 특성 중 $\\sqrt{d}$개만 무작위로 선택\n",
    "- 트리 간 상관성을 낮춰 분산 감소 효과 극대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트리 수(n_estimators)에 따른 랜덤 포레스트 성능\n",
    "n_trees_list = [1, 5, 10, 20, 50, 100, 200]\n",
    "rf_train_accs, rf_test_accs = [], []\n",
    "\n",
    "for n in n_trees_list:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_tr, y_tr)\n",
    "    rf_train_accs.append(rf.score(X_tr, y_tr))\n",
    "    rf_test_accs.append(rf.score(X_te, y_te))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 4))\n",
    "ax.plot(n_trees_list, rf_train_accs, 'o-', color='steelblue', lw=2, label='Train Accuracy')\n",
    "ax.plot(n_trees_list, rf_test_accs,  's-', color='tomato',    lw=2, label='Test Accuracy')\n",
    "ax.axhline(dt_full.score(X_te, y_te), color='gray', linestyle=':', lw=2,\n",
    "           label=f'단일 트리(제한없음) Test={dt_full.score(X_te, y_te):.3f}')\n",
    "ax.set_title('랜덤 포레스트 — 트리 수에 따른 정확도')\n",
    "ax.set_xlabel('트리 수 (n_estimators)')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0.7, 1.05)\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "rf_best = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_best.fit(X_tr, y_tr)\n",
    "print(f'랜덤 포레스트 (100 트리) Test Accuracy: {rf_best.score(X_te, y_te):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p3-md2",
   "metadata": {},
   "source": [
    "### 3-2. 특성 중요도 (Feature Importance)\n",
    "\n",
    "랜덤 포레스트는 **각 특성이 불순도를 얼마나 줄였는지** 로 중요도를 계산합니다.  \n",
    "Tic-Tac-Toe에서는 어느 칸이 가장 결정적일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p3-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 시각화\n",
    "importances = rf_best.feature_importances_\n",
    "sorted_idx  = np.argsort(importances)[::-1]\n",
    "sorted_feats = [feature_cols[i] for i in sorted_idx]\n",
    "sorted_imps  = importances[sorted_idx]\n",
    "\n",
    "# 중요도 막대 그래프\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "colors_imp = plt.cm.RdYlGn(sorted_imps / sorted_imps.max())\n",
    "bars = axes[0].bar(sorted_feats, sorted_imps, color=colors_imp, edgecolor='k', alpha=0.85)\n",
    "axes[0].set_title('랜덤 포레스트 특성 중요도 (높을수록 중요)')\n",
    "axes[0].set_xlabel('보드 위치')\n",
    "axes[0].set_ylabel('중요도 (Gini 감소량 평균)')\n",
    "for bar, val in zip(bars, sorted_imps):\n",
    "    axes[0].text(bar.get_x()+bar.get_width()/2, val+0.003,\n",
    "                 f'{val:.3f}', ha='center', fontsize=8)\n",
    "\n",
    "# 보드 위치별 중요도 히트맵\n",
    "pos_map = {\n",
    "    'top-left':0, 'top-middle':1, 'top-right':2,\n",
    "    'middle-left':3, 'middle-middle':4, 'middle-right':5,\n",
    "    'bottom-left':6, 'bottom-middle':7, 'bottom-right':8,\n",
    "}\n",
    "# 컬럼명이 다양할 수 있으므로 인덱스 기반으로\n",
    "board_grid = importances.reshape(3, 3)\n",
    "im = axes[1].imshow(board_grid, cmap='RdYlGn', vmin=0)\n",
    "pos_labels = [['TL', 'TM', 'TR'], ['ML', 'C', 'MR'], ['BL', 'BM', 'BR']]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[1].text(j, i, f'{pos_labels[i][j]}\\n{board_grid[i,j]:.3f}',\n",
    "                     ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('보드 위치별 중요도 히트맵\\n(초록=높음, 빨강=낮음)')\n",
    "axes[1].set_xticks([]); axes[1].set_yticks([])\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('가장 중요한 위치:', sorted_feats[0], f'(중요도: {sorted_imps[0]:.3f})')\n",
    "print('→ 중앙(C)이나 모서리가 틱택토에서 가장 전략적인 위치!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p4-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4. 앙상블 비교 — Bagging vs Boosting\n",
    "\n",
    "### 4-1. 두 전략의 차이\n",
    "\n",
    "| | **Bagging** | **Boosting** |\n",
    "|---|---|---|\n",
    "| 학습 방식 | 트리를 **병렬**로 독립 학습 | 트리를 **순차적**으로 학습 |\n",
    "| 초점 | 분산(variance) 감소 | 편향(bias) 감소 |\n",
    "| 틀린 샘플 | 균등 처리 | **가중치 증가** |\n",
    "| 대표 알고리즘 | Random Forest | AdaBoost, Gradient Boosting, XGBoost |\n",
    "| 과적합 위험 | 낮음 | 높음 (학습률 조정 필요) |\n",
    "\n",
    "### 4-2. Boosting 핵심 아이디어\n",
    "\n",
    "```\n",
    "약한 분류기 1 → 오분류된 샘플 가중치 ↑\n",
    "약한 분류기 2 → 오분류된 샘플 가중치 ↑  → 가중 합산 → 강한 분류기\n",
    "약한 분류기 3 → ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4가지 모델 비교\n",
    "models = {\n",
    "    '결정 트리\\n(제한없음)':      DecisionTreeClassifier(random_state=42),\n",
    "    f'결정 트리\\n(depth={best_depth})': DecisionTreeClassifier(max_depth=best_depth, random_state=42),\n",
    "    '랜덤 포레스트\\n(n=100)':     RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting\\n(n=100)': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost\\n(n=100)':          AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME'),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_tr, y_tr)\n",
    "    tr_acc = model.score(X_tr, y_tr)\n",
    "    te_acc = model.score(X_te, y_te)\n",
    "    cv_acc = cross_val_score(model, X, y, cv=5, scoring='accuracy').mean()\n",
    "    results[name] = dict(train=tr_acc, test=te_acc, cv5=cv_acc)\n",
    "    print(f'{name.replace(chr(10),\" \"):<30} Train={tr_acc:.3f}  Test={te_acc:.3f}  CV-5={cv_acc:.3f}')\n",
    "\n",
    "# 시각화\n",
    "short_names = ['DT\\n(무제한)', f'DT\\n(d={best_depth})', 'RF\\n(n=100)', 'GB\\n(n=100)', 'Ada\\n(n=100)']\n",
    "metrics_keys = ['train', 'test', 'cv5']\n",
    "labels_met   = ['Train Acc', 'Test Acc', '5-Fold CV Acc']\n",
    "colors_met   = ['steelblue', 'tomato', 'seagreen']\n",
    "\n",
    "x_pos  = np.arange(len(short_names))\n",
    "width  = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "for i, (key, label, color) in enumerate(zip(metrics_keys, labels_met, colors_met)):\n",
    "    vals = [list(results.values())[j][key] for j in range(len(results))]\n",
    "    bars = ax.bar(x_pos + (i-1)*width, vals, width, label=label,\n",
    "                  color=color, edgecolor='k', alpha=0.85)\n",
    "    for bar, v in zip(bars, vals):\n",
    "        ax.text(bar.get_x()+bar.get_width()/2, v+0.005,\n",
    "                f'{v:.2f}', ha='center', fontsize=7.5)\n",
    "\n",
    "ax.set_title('모델별 성능 비교 (Tic-Tac-Toe)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(short_names, fontsize=10)\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_ylim(0.6, 1.12)\n",
    "ax.legend(loc='lower right')\n",
    "ax.axhline(1.0, color='gray', linestyle=':', lw=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최고 성능 모델 상세 분석\n",
    "best_name  = max(results, key=lambda k: results[k]['cv5'])\n",
    "best_model = list(models.values())[list(models.keys()).index(best_name)]\n",
    "y_pred_best = best_model.predict(X_te)\n",
    "\n",
    "print(f'최고 모델: {best_name.replace(chr(10), \" \")}')\n",
    "print()\n",
    "print(classification_report(y_te, y_pred_best,\n",
    "                             target_names=['미승리(0)', 'X승리(1)']))\n",
    "\n",
    "# 혼동 행렬\n",
    "cm = confusion_matrix(y_te, y_pred_best)\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['미승리', 'X승리'],\n",
    "            yticklabels=['미승리', 'X승리'],\n",
    "            ax=ax, linewidths=0.5)\n",
    "ax.set_title(f'혼동 행렬 — {best_name.replace(chr(10), \" \")}')\n",
    "ax.set_xlabel('예측 클래스')\n",
    "ax.set_ylabel('실제 클래스')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-p4-md2",
   "metadata": {},
   "source": [
    "### 4-3. 편향-분산 트레이드오프 시각화\n",
    "\n",
    "앙상블 방법이 어떻게 분산을 줄이는지 직관적으로 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-p4-code3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부트스트랩 샘플별 트리 예측 분산 시각화\n",
    "N_BOOTSTRAP = 20\n",
    "preds_single = np.zeros((N_BOOTSTRAP, len(X_te)))\n",
    "\n",
    "for b in range(N_BOOTSTRAP):\n",
    "    idx = rng.integers(0, len(X_tr), size=len(X_tr))\n",
    "    dt_b = DecisionTreeClassifier(random_state=b)\n",
    "    dt_b.fit(X_tr[idx], y_tr[idx])\n",
    "    preds_single[b] = dt_b.predict(X_te)\n",
    "\n",
    "# 첫 20개 테스트 샘플에 대한 예측 분포\n",
    "n_show    = 20\n",
    "ensemble_pred = (preds_single[:, :n_show].mean(axis=0) >= 0.5).astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(13, 5))\n",
    "\n",
    "im = axes[0].imshow(preds_single[:, :n_show], cmap='RdBu', aspect='auto',\n",
    "                    vmin=0, vmax=1)\n",
    "axes[0].set_title(f'부트스트랩 트리 {N_BOOTSTRAP}개의 예측값 (파랑=X승리, 빨강=미승리)')\n",
    "axes[0].set_xlabel('테스트 샘플 인덱스')\n",
    "axes[0].set_ylabel('트리 번호')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "x_arr   = np.arange(n_show)\n",
    "vote_ratio = preds_single[:, :n_show].mean(axis=0)\n",
    "axes[1].bar(x_arr, vote_ratio, color=['steelblue' if v >= 0.5 else 'tomato' for v in vote_ratio],\n",
    "            edgecolor='k', alpha=0.85)\n",
    "axes[1].axhline(0.5, color='black', lw=1.5, linestyle='--', label='임계값 0.5')\n",
    "for i, (v, gt) in enumerate(zip(vote_ratio, y_te[:n_show])):\n",
    "    marker = '✓' if (v>=0.5)==gt else '✗'\n",
    "    axes[1].text(i, v + 0.04, marker, ha='center', fontsize=9,\n",
    "                 color='green' if marker=='✓' else 'red')\n",
    "axes[1].set_title('앙상블 투표 비율 (✓=정답, ✗=오답)')\n",
    "axes[1].set_xlabel('테스트 샘플')\n",
    "axes[1].set_ylabel(\"'X승리' 투표 비율\")\n",
    "axes[1].set_ylim(0, 1.25)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "single_accs = [(preds_single[b, :] == y_te).mean() for b in range(N_BOOTSTRAP)]\n",
    "print(f'개별 트리 평균 정확도: {np.mean(single_accs):.3f} ± {np.std(single_accs):.3f}')\n",
    "print(f'앙상블 (다수결) 정확도: {(ensemble_pred == y_te[:n_show]).mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md1",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise\n",
    "\n",
    "### Exercise 1. Gini vs Entropy 분할 기준 비교\n",
    "\n",
    "`criterion='gini'`와 `criterion='entropy'` 두 가지 기준으로 결정 트리를 학습하고,  \n",
    "`max_depth=1`부터 `15`까지 Test Accuracy를 비교하는 그래프를 그리세요.  \n",
    "어느 기준이 이 데이터에 더 적합한가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Gini vs Entropy 비교\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md2",
   "metadata": {},
   "source": [
    "### Exercise 2. `min_samples_leaf`로 가지치기\n",
    "\n",
    "`max_depth` 외에 `min_samples_leaf` (리프 노드의 최소 샘플 수) 도 가지치기에 사용됩니다.  \n",
    "`min_samples_leaf = 1, 2, 5, 10, 20, 50` 각각에 대해 Train/Test Accuracy를 비교하고,  \n",
    "트리 크기(리프 수)도 함께 시각화하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: min_samples_leaf 실험\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-ex-md3",
   "metadata": {},
   "source": [
    "### Exercise 3. (도전) 랜덤 포레스트 하이퍼파라미터 탐색\n",
    "\n",
    "아래 하이퍼파라미터 조합으로 **그리드 탐색**을 수행하고 최적 조합을 찾으세요.\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth':    [None, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n",
    "```\n",
    "\n",
    "힌트: `sklearn.model_selection.GridSearchCV`를 사용하세요.  \n",
    "5-fold 교차 검증 기준 최고 Test Accuracy와 파라미터 조합을 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ex3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: GridSearchCV\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c-summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| 개념 | 핵심 내용 |\n",
    "|---|---|\n",
    "| **Gini 불순도** | $1 - \\sum p_k^2$ — 분할 품질 측정, sklearn 기본값 |\n",
    "| **엔트로피** | $-\\sum p_k \\log_2 p_k$ — 정보 이론 기반 분할 기준 |\n",
    "| **정보 이득** | 부모 불순도 − 자식 가중 불순도 — 클수록 좋은 분할 |\n",
    "| **가지치기** | `max_depth`, `min_samples_leaf` 등으로 과적합 방지 |\n",
    "| **배깅** | 부트스트랩 샘플로 트리 병렬 학습 후 다수결 |\n",
    "| **랜덤 포레스트** | 배깅 + 무작위 특성 선택 → 분산 감소 |\n",
    "| **특성 중요도** | Gini 감소량 평균 — 어떤 특성이 결정적인지 파악 |\n",
    "| **부스팅** | 오분류 샘플에 가중치 증가, 순차 학습 → 편향 감소 |\n",
    "| **Gradient Boosting** | 잔차(residual)를 반복 학습하는 강력한 앙상블 |\n",
    "| **편향-분산** | 단일 트리=고분산, 앙상블=분산 감소, 부스팅=편향 감소 |\n",
    "\n",
    "---\n",
    "\n",
    "**다음 강의 (Week 8):** 신경망 — 다층 퍼셉트론, 활성화 함수, 역전파 알고리즘"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
